{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ssd_v2_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYWXtvNUFoN3"
      },
      "outputs": [],
      "source": [
        "repo_url = 'https://github.com/roboflow-ai/tensorflow-object-detection-faster-rcnn'\n",
        "\n",
        "num_steps = 15000  # 200000 to improve\n",
        "\n",
        "num_eval_steps = 50\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'rfcn_resnet101': {\n",
        "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
        "        'batch_size': 8\n",
        " \n",
        "    },    \n",
        "}\n",
        "\n",
        "\n",
        "selected_model = 'ssd_mobilenet_v2'\n",
        "\n",
        "\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BKKOeV7Fo0U",
        "outputId": "8b6e2e1c-ab06-476c-9760-44b5ce5f0f94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "%cd /content\n",
        "\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "\n",
        "!git clone {repo_url}\n",
        "%cd {repo_dir_path}\n",
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7Y4WeHEFtAD",
        "outputId": "6df464cb-e50a-4ea1-b1b5-fcb710bda976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'tensorflow-object-detection-faster-rcnn'...\n",
            "remote: Enumerating objects: 885, done.\u001b[K\n",
            "remote: Total 885 (delta 0), reused 0 (delta 0), pack-reused 885\u001b[K\n",
            "Receiving objects: 100% (885/885), 24.83 MiB | 9.92 MiB/s, done.\n",
            "Resolving deltas: 100% (428/428), done.\n",
            "/content/tensorflow-object-detection-faster-rcnn\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "\n",
        "!pip install tf_slim\n",
        "\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "\n",
        "!pip install -q pycocotools\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "metadata": {
        "id": "aWnIBwb6FvRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "models에 images 폴더 생성"
      ],
      "metadata": {
        "id": "uVNtHYRz1dVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/models/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opy2Ke0j6VJ8",
        "outputId": "fc9c82cf-7ddd-4cfe-d0e3-47223ba22186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir images\n",
        "%cd /content/models/images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V07fC_Ql1hFR",
        "outputId": "b9e4f009-ad4e-42a4-be2c-ae00cc10d147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘images’: File exists\n",
            "/content/models/images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L \"https://app.roboflow.com/ds/atyvPjFTaz?key=JeMfxlYTwq\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n"
      ],
      "metadata": {
        "id": "GVgiTcxcF_nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training set\n",
        "%ls train"
      ],
      "metadata": {
        "id": "59tOq_3fF_lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test set\n",
        "%ls test"
      ],
      "metadata": {
        "id": "5DN0JQFAF_kM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/models/\n",
        "!mkdir data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTdnqaX96O8O",
        "outputId": "aca0cc9a-13a4-45d8-93e6-c9a6544abdb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "/models 에 data 폴더 생성 \n",
        "data 폴더 안에 train_labels.csv , test_labels.csv 넣기 \n",
        "- research/object_detection/dataset_tools/generate_tfrecord.py 넣기\n"
      ],
      "metadata": {
        "id": "bXd8zT7l1Sku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python research/object_detection/dataset_tools/generate_tfrecord.py --csv_input=data/train_labels.csv --output_path=train.record --image_dir=images/train\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTVpKZ-d5lBr",
        "outputId": "3da0942e-15df-4bbb-ce37-7a1cd3e92d71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From research/object_detection/dataset_tools/generate_tfrecord.py:100: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From research/object_detection/dataset_tools/generate_tfrecord.py:86: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0418 13:26:34.525115 140343152342912 module_wrapper.py:139] From research/object_detection/dataset_tools/generate_tfrecord.py:86: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "Successfully created the TFRecords: /content/models/train.record\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python research/object_detection/dataset_tools/generate_tfrecord.py --csv_input=data/test_labels.csv --output_path=test.record --image_dir=images/test\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOd5ellw7J3y",
        "outputId": "30d8d4c3-0d98-482a-bdcd-c746a7ace4ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From research/object_detection/dataset_tools/generate_tfrecord.py:100: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From research/object_detection/dataset_tools/generate_tfrecord.py:86: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0418 13:28:31.407375 139831479019392 module_wrapper.py:139] From research/object_detection/dataset_tools/generate_tfrecord.py:86: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "Successfully created the TFRecords: /content/models/test.record\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- train, test.record 각각 fire.record로 이름 변경후 아래 경로로 이동\n"
      ],
      "metadata": {
        "id": "rz9ieJZy2vGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_record_fname = '/content/tensorflow-object-detection-faster-rcnn/data/test/fire.record'\n",
        "train_record_fname = '/content/tensorflow-object-detection-faster-rcnn/data/train/fire.record'\n",
        "label_map_pbtxt_fname = '/content/tensorflow-object-detection-faster-rcnn/data/train/fire_label_map.pbtxt'"
      ],
      "metadata": {
        "id": "YpiSilCKF_iZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/models/research\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/models/research/pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcdAzFUzF_fT",
        "outputId": "8b5fc86e-84c0-4fa8-ca33-cadc87649579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo {DEST_DIR}\n",
        "!ls -alh {DEST_DIR}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnOWsiQ4F_dq",
        "outputId": "f8fad69a-20fc-476e-8871-42c135d7a4a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/pretrained_model\n",
            "total 135M\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 .\n",
            "drwxr-xr-x 23 root   root  4.0K Apr 18 13:29 ..\n",
            "-rw-r--r--  1 345018 89939   77 Mar 30  2018 checkpoint\n",
            "-rw-r--r--  1 345018 89939  67M Mar 30  2018 frozen_inference_graph.pb\n",
            "-rw-r--r--  1 345018 89939  65M Mar 30  2018 model.ckpt.data-00000-of-00001\n",
            "-rw-r--r--  1 345018 89939  15K Mar 30  2018 model.ckpt.index\n",
            "-rw-r--r--  1 345018 89939 3.4M Mar 30  2018 model.ckpt.meta\n",
            "-rw-r--r--  1 345018 89939 4.2K Mar 30  2018 pipeline.config\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 saved_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "fine_tune_checkpoint"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "M8kAx1uSF_cC",
        "outputId": "ecf35b20-f1f5-4674-9915-2953f33f9e42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/models/research/pretrained_model/model.ckpt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"
      ],
      "metadata": {
        "id": "vWqbElavF_aX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())"
      ],
      "metadata": {
        "id": "eqlOzrj8F_ZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- fire_label_map.pbtxt 데이터 생성후 todf/data/train 에 이동\n"
      ],
      "metadata": {
        "id": "ALkZ8Q4y3kVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    \n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    \n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    \n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    \n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    \n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    \n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    f.write(s)"
      ],
      "metadata": {
        "id": "QJUT430aF_Xa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat {pipeline_fname}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVT3nQlMF_Vh",
        "outputId": "af42a7f7-97a3-4f7c-df8b-96289e9992f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# SSD with Mobilenet v2 configuration for MSCOCO Dataset.\n",
            "# Users should configure the fine_tune_checkpoint field in the train config as\n",
            "# well as the label_map_path and input_path fields in the train_input_reader and\n",
            "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
            "# should be configured.\n",
            "\n",
            "model {\n",
            "  ssd {\n",
            "    num_classes: 1\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    anchor_generator {\n",
            "      ssd_anchor_generator {\n",
            "        num_layers: 6\n",
            "        min_scale: 0.2\n",
            "        max_scale: 0.95\n",
            "        aspect_ratios: 1.0\n",
            "        aspect_ratios: 2.0\n",
            "        aspect_ratios: 0.5\n",
            "        aspect_ratios: 3.0\n",
            "        aspect_ratios: 0.3333\n",
            "      }\n",
            "    }\n",
            "    image_resizer {\n",
            "      fixed_shape_resizer {\n",
            "        height: 300\n",
            "        width: 300\n",
            "      }\n",
            "    }\n",
            "    box_predictor {\n",
            "      convolutional_box_predictor {\n",
            "        min_depth: 0\n",
            "        max_depth: 0\n",
            "        num_layers_before_predictor: 0\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 0.8\n",
            "        kernel_size: 1\n",
            "        box_code_size: 4\n",
            "        apply_sigmoid_to_scores: false\n",
            "        conv_hyperparams {\n",
            "          activation: RELU_6,\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.00004\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            truncated_normal_initializer {\n",
            "              stddev: 0.03\n",
            "              mean: 0.0\n",
            "            }\n",
            "          }\n",
            "          batch_norm {\n",
            "            train: true,\n",
            "            scale: true,\n",
            "            center: true,\n",
            "            decay: 0.9997,\n",
            "            epsilon: 0.001,\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'ssd_mobilenet_v2'\n",
            "      min_depth: 16\n",
            "      depth_multiplier: 1.0\n",
            "      conv_hyperparams {\n",
            "        activation: RELU_6,\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 0.00004\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          truncated_normal_initializer {\n",
            "            stddev: 0.03\n",
            "            mean: 0.0\n",
            "          }\n",
            "        }\n",
            "        batch_norm {\n",
            "          train: true,\n",
            "          scale: true,\n",
            "          center: true,\n",
            "          decay: 0.9997,\n",
            "          epsilon: 0.001,\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    loss {\n",
            "      classification_loss {\n",
            "        weighted_sigmoid {\n",
            "        }\n",
            "      }\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "        }\n",
            "      }\n",
            "      hard_example_miner {\n",
            "        num_hard_examples: 3000\n",
            "        iou_threshold: 0.99\n",
            "        loss_type: CLASSIFICATION\n",
            "        max_negatives_per_positive: 3\n",
            "        min_negatives_per_image: 3\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 1e-8\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  batch_size: 12\n",
            "  optimizer {\n",
            "    rms_prop_optimizer: {\n",
            "      learning_rate: {\n",
            "        exponential_decay_learning_rate {\n",
            "          initial_learning_rate: 0.004\n",
            "          decay_steps: 800720\n",
            "          decay_factor: 0.95\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "      decay: 0.9\n",
            "      epsilon: 1.0\n",
            "    }\n",
            "  }\n",
            "  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n",
            "  fine_tune_checkpoint_type:  \"detection\"\n",
            "  # Note: The below line limits the training process to 200K steps, which we\n",
            "  # empirically found to be sufficient enough to train the pets dataset. This\n",
            "  # effectively bypasses the learning rate schedule (the learning rate will\n",
            "  # never decay). Remove the below line to train indefinitely.\n",
            "  num_steps: 100000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    ssd_random_crop {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/fire.record\"\n",
            "  }\n",
            "  label_map_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/fire_label_map.pbtxt\"\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  num_examples: 8000\n",
            "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
            "  # Remove the below line to evaluate indefinitely.\n",
            "  max_evals: 10\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/tensorflow-object-detection-faster-rcnn/data/test/fire.record\"\n",
            "  }\n",
            "  label_map_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/fire_label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_readers: 1\n",
            "}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir training\n",
        "model_dir = 'training/'\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "BF9bIo4_F_T7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6f20d39-a5b8-4130-9e7d-e50ff2355b28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘training’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qxu2vhet7zPJ",
        "outputId": "d07f4b33-7444-4148-e0b7-96f36b54270e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5libVI7F_Sd",
        "outputId": "b66c00c9-4690-4d1b-f5f5-f17ea90b868a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-18 13:33:37--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.161.241.46, 18.205.222.128, 54.237.133.81, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.161.241.46|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13832437 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  5.52MB/s    in 2.4s    \n",
            "\n",
            "2022-04-18 13:33:41 (5.52 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13832437/13832437]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LOG_DIR = model_dir\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "metadata": {
        "id": "X6gIv9xOF_Q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "metadata": {
        "id": "vBGLcjM-F_PX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtUyAqkXF_Ns",
        "outputId": "0c1ffe8f-1c7e-4b7c-dbf2-bd12c284e78a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://94a8-34-124-249-144.ngrok.io\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lvis"
      ],
      "metadata": {
        "id": "OnhW0IW3InK7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bd17c2c-0b54-4507-fa13-e3505da82253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.15.0)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.11.0)\n",
            "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from lvis) (3.2.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis) (4.1.2.30)\n",
            "Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (3.0.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (2.8.2)\n",
            "Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.29.28)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.21.5)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.1.0->lvis) (4.1.1)\n",
            "Installing collected packages: lvis\n",
            "Successfully installed lvis-0.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy==1.18.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "hRQNforEIve3",
        "outputId": "fc6bf413-e378-4fae-e30f-5bc9b5863a1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.18.4\n",
            "  Downloading numpy-1.18.4-cp37-cp37m-manylinux1_x86_64.whl (20.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2 MB 1.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.5\n",
            "    Uninstalling numpy-1.21.5:\n",
            "      Successfully uninstalled numpy-1.21.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lucid 0.3.10 requires umap-learn, which is not installed.\n",
            "tensorflow 1.15.2 requires gast==0.2.2, but you have gast 0.5.3 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.18.4 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.18.4 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.2 which is incompatible.\n",
            "jaxlib 0.3.2+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.18.4 which is incompatible.\n",
            "jax 0.3.4 requires numpy>=1.19, but you have numpy 1.18.4 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.18.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall pycocotools -y\n",
        "!pip install --no-cache-dir pycocotools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwP8YbpEJCNK",
        "outputId": "f0e79fb8-1674-4c97-eac5-cbf116fa2a81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: pycocotools 2.0.4\n",
            "Uninstalling pycocotools-2.0.4:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/pycocotools-2.0.4.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/pycocotools/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled pycocotools-2.0.4\n",
            "Collecting pycocotools\n",
            "  Downloading pycocotools-2.0.4.tar.gz (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 31.6 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pycocotools) (1.18.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.0->pycocotools) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools) (1.15.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0.4-cp37-cp37m-linux_x86_64.whl size=265217 sha256=644a104c90c6ebe0bef132bcde0eda84914942591200d2d8bebc046947b865c2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-q2btsbch/wheels/a3/5f/fa/f011e578cc76e1fc5be8dce30b3eb9fd00f337e744b3bba59b\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "Successfully installed pycocotools-2.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aE8g6DEN8SFb",
        "outputId": "e7901292-818d-4b5b-8369-5d9d652c9738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps=15000 \\\n",
        "    --sample_1_of_n_eval_examples=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fyeRixjF_Mo",
        "outputId": "f906dec2-25a9-4909-be2a-3a59597e350d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0418 13:34:45.329842 139739744683904 model_lib.py:839] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 15000\n",
            "I0418 13:34:45.330035 139739744683904 config_util.py:552] Maybe overwriting train_steps: 15000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0418 13:34:45.330105 139739744683904 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0418 13:34:45.330159 139739744683904 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0418 13:34:45.330212 139739744683904 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0418 13:34:45.330284 139739744683904 model_lib.py:855] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "I0418 13:34:45.330345 139739744683904 model_lib.py:892] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1739569c10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0418 13:34:45.330698 139739744683904 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1739569c10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f1739521320>) includes params argument, but params are not passed to Estimator.\n",
            "W0418 13:34:45.330863 139739744683904 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f1739521320>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0418 13:34:45.331244 139739744683904 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0418 13:34:45.331375 139739744683904 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0418 13:34:45.331539 139739744683904 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0418 13:34:45.341933 139739744683904 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/train/fire.record']\n",
            "I0418 13:34:45.361934 139739744683904 dataset_builder.py:162] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/train/fire.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/train/fire.record']\n",
            "I0418 13:34:45.379288 139739744683904 dataset_builder.py:79] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/train/fire.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0418 13:34:45.379393 139739744683904 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0418 13:34:45.379447 139739744683904 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0418 13:34:45.383832 139739744683904 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0418 13:34:45.401423 139739744683904 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f1739532e50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W0418 13:34:45.442582 139739744683904 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f1739532e50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7f17395217a0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "W0418 13:34:45.611657 139739744683904 ag_logging.py:146] Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7f17395217a0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:114: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0418 13:34:45.612704 139739744683904 deprecation.py:323] From /content/models/research/object_detection/inputs.py:114: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:100: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0418 13:34:45.621150 139739744683904 deprecation.py:323] From /content/models/research/object_detection/inputs.py:100: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:200: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0418 13:34:45.711662 139739744683904 deprecation.py:323] From /content/models/research/object_detection/core/preprocessor.py:200: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:290: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0418 13:34:46.381592 139739744683904 deprecation.py:323] From /content/models/research/object_detection/inputs.py:290: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0418 13:34:46.895097 139739744683904 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0418 13:34:47.061815 139739744683904 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 13:34:49.299034 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 13:34:49.327521 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 13:34:49.354005 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 13:34:49.383018 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 13:34:49.409801 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 13:34:49.437752 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0418 13:34:53.172901 139739744683904 deprecation.py:506] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0418 13:34:58.647741 139739744683904 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0418 13:34:58.648959 139739744683904 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0418 13:35:01.386094 139739744683904 monitored_session.py:240] Graph was finalized.\n",
            "2022-04-18 13:35:01.396628: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2022-04-18 13:35:01.396951: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55613583a700 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-04-18 13:35:01.396983: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2022-04-18 13:35:01.400854: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2022-04-18 13:35:01.674991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 13:35:01.675653: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55613583a380 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2022-04-18 13:35:01.675688: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2022-04-18 13:35:01.676563: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 13:35:01.677101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-04-18 13:35:01.687347: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-04-18 13:35:01.824052: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2022-04-18 13:35:01.874347: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2022-04-18 13:35:01.889157: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2022-04-18 13:35:02.051765: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-04-18 13:35:02.084529: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2022-04-18 13:35:02.357363: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-04-18 13:35:02.357558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 13:35:02.358254: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 13:35:02.358799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2022-04-18 13:35:02.361091: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-04-18 13:35:02.362471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-04-18 13:35:02.362501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2022-04-18 13:35:02.362511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2022-04-18 13:35:02.363241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 13:35:02.363859: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 13:35:02.364375: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-04-18 13:35:02.364417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0418 13:35:08.232963 139739744683904 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0418 13:35:08.514637 139739744683904 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.\n",
            "I0418 13:35:16.496476 139739744683904 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n",
            "2022-04-18 13:35:23.372406: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-04-18 13:35:25.652184: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "INFO:tensorflow:loss = 12.882708, step = 0\n",
            "I0418 13:35:28.051684 139739744683904 basic_session_run_hooks.py:262] loss = 12.882708, step = 0\n",
            "INFO:tensorflow:global_step/sec: 4.88769\n",
            "I0418 13:35:48.510322 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 4.88769\n",
            "INFO:tensorflow:loss = 7.5603127, step = 100 (20.460 sec)\n",
            "I0418 13:35:48.511150 139739744683904 basic_session_run_hooks.py:260] loss = 7.5603127, step = 100 (20.460 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.73901\n",
            "I0418 13:36:05.934936 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.73901\n",
            "INFO:tensorflow:loss = 7.431539, step = 200 (17.425 sec)\n",
            "I0418 13:36:05.935973 139739744683904 basic_session_run_hooks.py:260] loss = 7.431539, step = 200 (17.425 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.66589\n",
            "I0418 13:36:23.584407 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.66589\n",
            "INFO:tensorflow:loss = 6.5889, step = 300 (17.649 sec)\n",
            "I0418 13:36:23.585464 139739744683904 basic_session_run_hooks.py:260] loss = 6.5889, step = 300 (17.649 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.71827\n",
            "I0418 13:36:41.072211 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.71827\n",
            "INFO:tensorflow:loss = 7.194062, step = 400 (17.488 sec)\n",
            "I0418 13:36:41.073141 139739744683904 basic_session_run_hooks.py:260] loss = 7.194062, step = 400 (17.488 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.72441\n",
            "I0418 13:36:58.541251 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.72441\n",
            "INFO:tensorflow:loss = 9.334116, step = 500 (17.469 sec)\n",
            "I0418 13:36:58.542182 139739744683904 basic_session_run_hooks.py:260] loss = 9.334116, step = 500 (17.469 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.73167\n",
            "I0418 13:37:15.988193 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.73167\n",
            "INFO:tensorflow:loss = 7.251371, step = 600 (17.447 sec)\n",
            "I0418 13:37:15.989014 139739744683904 basic_session_run_hooks.py:260] loss = 7.251371, step = 600 (17.447 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.69739\n",
            "I0418 13:37:33.540066 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.69739\n",
            "INFO:tensorflow:loss = 5.8644605, step = 700 (17.552 sec)\n",
            "I0418 13:37:33.540983 139739744683904 basic_session_run_hooks.py:260] loss = 5.8644605, step = 700 (17.552 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.66461\n",
            "I0418 13:37:51.193565 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.66461\n",
            "INFO:tensorflow:loss = 6.246955, step = 800 (17.653 sec)\n",
            "I0418 13:37:51.194390 139739744683904 basic_session_run_hooks.py:260] loss = 6.246955, step = 800 (17.653 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.6548\n",
            "I0418 13:38:08.877665 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.6548\n",
            "INFO:tensorflow:loss = 5.7540503, step = 900 (17.684 sec)\n",
            "I0418 13:38:08.878577 139739744683904 basic_session_run_hooks.py:260] loss = 5.7540503, step = 900 (17.684 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.62262\n",
            "I0418 13:38:26.662997 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.62262\n",
            "INFO:tensorflow:loss = 6.0703926, step = 1000 (17.785 sec)\n",
            "I0418 13:38:26.664026 139739744683904 basic_session_run_hooks.py:260] loss = 6.0703926, step = 1000 (17.785 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.69356\n",
            "I0418 13:38:44.226688 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.69356\n",
            "INFO:tensorflow:loss = 6.485366, step = 1100 (17.564 sec)\n",
            "I0418 13:38:44.227607 139739744683904 basic_session_run_hooks.py:260] loss = 6.485366, step = 1100 (17.564 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.66409\n",
            "I0418 13:39:01.881761 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.66409\n",
            "INFO:tensorflow:loss = 5.5126853, step = 1200 (17.655 sec)\n",
            "I0418 13:39:01.882658 139739744683904 basic_session_run_hooks.py:260] loss = 5.5126853, step = 1200 (17.655 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.6508\n",
            "I0418 13:39:19.578367 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.6508\n",
            "INFO:tensorflow:loss = 5.662854, step = 1300 (17.697 sec)\n",
            "I0418 13:39:19.579252 139739744683904 basic_session_run_hooks.py:260] loss = 5.662854, step = 1300 (17.697 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.66121\n",
            "I0418 13:39:37.242433 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.66121\n",
            "INFO:tensorflow:loss = 5.3406596, step = 1400 (17.664 sec)\n",
            "I0418 13:39:37.243247 139739744683904 basic_session_run_hooks.py:260] loss = 5.3406596, step = 1400 (17.664 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.64018\n",
            "I0418 13:39:54.972387 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.64018\n",
            "INFO:tensorflow:loss = 5.1932206, step = 1500 (17.730 sec)\n",
            "I0418 13:39:54.973597 139739744683904 basic_session_run_hooks.py:260] loss = 5.1932206, step = 1500 (17.730 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.59048\n",
            "I0418 13:40:12.859930 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.59048\n",
            "INFO:tensorflow:loss = 5.7376075, step = 1600 (17.887 sec)\n",
            "I0418 13:40:12.860835 139739744683904 basic_session_run_hooks.py:260] loss = 5.7376075, step = 1600 (17.887 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.59373\n",
            "I0418 13:40:30.737071 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.59373\n",
            "INFO:tensorflow:loss = 6.1349463, step = 1700 (17.877 sec)\n",
            "I0418 13:40:30.737988 139739744683904 basic_session_run_hooks.py:260] loss = 6.1349463, step = 1700 (17.877 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.59616\n",
            "I0418 13:40:48.606443 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.59616\n",
            "INFO:tensorflow:loss = 6.195519, step = 1800 (17.869 sec)\n",
            "I0418 13:40:48.607247 139739744683904 basic_session_run_hooks.py:260] loss = 6.195519, step = 1800 (17.869 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.59459\n",
            "I0418 13:41:06.480840 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.59459\n",
            "INFO:tensorflow:loss = 5.6926184, step = 1900 (17.874 sec)\n",
            "I0418 13:41:06.481627 139739744683904 basic_session_run_hooks.py:260] loss = 5.6926184, step = 1900 (17.874 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.60481\n",
            "I0418 13:41:24.322675 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.60481\n",
            "INFO:tensorflow:loss = 5.2499876, step = 2000 (17.842 sec)\n",
            "I0418 13:41:24.323759 139739744683904 basic_session_run_hooks.py:260] loss = 5.2499876, step = 2000 (17.842 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.57674\n",
            "I0418 13:41:42.254295 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.57674\n",
            "INFO:tensorflow:loss = 6.828822, step = 2100 (17.931 sec)\n",
            "I0418 13:41:42.255253 139739744683904 basic_session_run_hooks.py:260] loss = 6.828822, step = 2100 (17.931 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.61045\n",
            "I0418 13:42:00.078204 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.61045\n",
            "INFO:tensorflow:loss = 6.242209, step = 2200 (17.824 sec)\n",
            "I0418 13:42:00.079313 139739744683904 basic_session_run_hooks.py:260] loss = 6.242209, step = 2200 (17.824 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.58471\n",
            "I0418 13:42:17.984245 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.58471\n",
            "INFO:tensorflow:loss = 6.2547307, step = 2300 (17.906 sec)\n",
            "I0418 13:42:17.985103 139739744683904 basic_session_run_hooks.py:260] loss = 6.2547307, step = 2300 (17.906 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.61153\n",
            "I0418 13:42:35.804714 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.61153\n",
            "INFO:tensorflow:loss = 6.725003, step = 2400 (17.821 sec)\n",
            "I0418 13:42:35.805640 139739744683904 basic_session_run_hooks.py:260] loss = 6.725003, step = 2400 (17.821 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.60413\n",
            "I0418 13:42:53.648686 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.60413\n",
            "INFO:tensorflow:loss = 5.876518, step = 2500 (17.844 sec)\n",
            "I0418 13:42:53.649630 139739744683904 basic_session_run_hooks.py:260] loss = 5.876518, step = 2500 (17.844 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.56921\n",
            "I0418 13:43:11.604550 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.56921\n",
            "INFO:tensorflow:loss = 6.6782494, step = 2600 (17.956 sec)\n",
            "I0418 13:43:11.605492 139739744683904 basic_session_run_hooks.py:260] loss = 6.6782494, step = 2600 (17.956 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.59263\n",
            "I0418 13:43:29.485226 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.59263\n",
            "INFO:tensorflow:loss = 5.663017, step = 2700 (17.881 sec)\n",
            "I0418 13:43:29.486206 139739744683904 basic_session_run_hooks.py:260] loss = 5.663017, step = 2700 (17.881 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.60536\n",
            "I0418 13:43:47.325296 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.60536\n",
            "INFO:tensorflow:loss = 6.084769, step = 2800 (17.840 sec)\n",
            "I0418 13:43:47.326356 139739744683904 basic_session_run_hooks.py:260] loss = 6.084769, step = 2800 (17.840 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.58555\n",
            "I0418 13:44:05.228622 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.58555\n",
            "INFO:tensorflow:loss = 5.7907033, step = 2900 (17.903 sec)\n",
            "I0418 13:44:05.229535 139739744683904 basic_session_run_hooks.py:260] loss = 5.7907033, step = 2900 (17.903 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.56969\n",
            "I0418 13:44:23.182980 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.56969\n",
            "INFO:tensorflow:loss = 6.1462502, step = 3000 (17.955 sec)\n",
            "I0418 13:44:23.184077 139739744683904 basic_session_run_hooks.py:260] loss = 6.1462502, step = 3000 (17.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.5465\n",
            "I0418 13:44:41.212364 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.5465\n",
            "INFO:tensorflow:loss = 5.915639, step = 3100 (18.029 sec)\n",
            "I0418 13:44:41.213287 139739744683904 basic_session_run_hooks.py:260] loss = 5.915639, step = 3100 (18.029 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.59742\n",
            "I0418 13:44:59.077721 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.59742\n",
            "INFO:tensorflow:loss = 5.2084894, step = 3200 (17.865 sec)\n",
            "I0418 13:44:59.078719 139739744683904 basic_session_run_hooks.py:260] loss = 5.2084894, step = 3200 (17.865 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.58921\n",
            "I0418 13:45:16.969350 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.58921\n",
            "INFO:tensorflow:loss = 5.771833, step = 3300 (17.892 sec)\n",
            "I0418 13:45:16.970238 139739744683904 basic_session_run_hooks.py:260] loss = 5.771833, step = 3300 (17.892 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 3310 into training/model.ckpt.\n",
            "I0418 13:45:18.551276 139739744683904 basic_session_run_hooks.py:606] Saving checkpoints for 3310 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/fire.record']\n",
            "I0418 13:45:19.766693 139739744683904 dataset_builder.py:162] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/fire.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/fire.record']\n",
            "I0418 13:45:19.774585 139739744683904 dataset_builder.py:79] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/fire.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0418 13:45:19.774722 139739744683904 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f1731fdcd50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W0418 13:45:19.833069 139739744683904 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f1731fdcd50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f173207ef80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "W0418 13:45:19.996239 139739744683904 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f173207ef80> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0418 13:45:20.470777 139739744683904 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 13:45:22.376259 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 13:45:22.404343 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 13:45:22.430943 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 13:45:22.457567 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 13:45:22.484792 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 13:45:22.511690 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0418 13:45:23.141383 139739744683904 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0418 13:45:23.329814 139739744683904 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0418 13:45:23.784786 139739744683904 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2022-04-18T13:45:23Z\n",
            "I0418 13:45:23.799610 139739744683904 evaluation.py:255] Starting evaluation at 2022-04-18T13:45:23Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0418 13:45:24.168248 139739744683904 monitored_session.py:240] Graph was finalized.\n",
            "2022-04-18 13:45:24.169301: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 13:45:24.169774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-04-18 13:45:24.169911: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-04-18 13:45:24.169942: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2022-04-18 13:45:24.169967: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2022-04-18 13:45:24.169996: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2022-04-18 13:45:24.170024: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-04-18 13:45:24.170046: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2022-04-18 13:45:24.170074: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-04-18 13:45:24.170158: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 13:45:24.170618: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 13:45:24.171027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2022-04-18 13:45:24.171073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-04-18 13:45:24.171086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2022-04-18 13:45:24.171095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2022-04-18 13:45:24.171192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 13:45:24.171638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 13:45:24.172056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-3310\n",
            "I0418 13:45:24.172973 139739744683904 saver.py:1284] Restoring parameters from training/model.ckpt-3310\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0418 13:45:24.967837 139739744683904 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0418 13:45:25.079291 139739744683904 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 849 images.\n",
            "I0418 13:45:41.390861 139737318303488 coco_evaluation.py:293] Performing evaluation on 849 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0418 13:45:41.393263 139737318303488 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.06s)\n",
            "I0418 13:45:41.456473 139737318303488 coco_tools.py:138] DONE (t=0.06s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=5.33s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.75s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.031\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.009\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.009\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.063\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.203\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.332\n",
            "INFO:tensorflow:Finished evaluation at 2022-04-18-13:45:47\n",
            "I0418 13:45:47.702039 139739744683904 evaluation.py:275] Finished evaluation at 2022-04-18-13:45:47\n",
            "INFO:tensorflow:Saving dict for global step 3310: DetectionBoxes_Precision/mAP = 0.0061296835, DetectionBoxes_Precision/mAP (large) = 0.009230337, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.030515013, DetectionBoxes_Precision/mAP@.75IOU = 0.0016030894, DetectionBoxes_Recall/AR@1 = 0.009482072, DetectionBoxes_Recall/AR@10 = 0.06270916, DetectionBoxes_Recall/AR@100 = 0.20294821, DetectionBoxes_Recall/AR@100 (large) = 0.332073, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 5.7989855, Loss/localization_loss = 2.835687, Loss/regularization_loss = 0.30786204, Loss/total_loss = 8.942536, global_step = 3310, learning_rate = 0.004, loss = 8.942536\n",
            "I0418 13:45:47.702287 139739744683904 estimator.py:2049] Saving dict for global step 3310: DetectionBoxes_Precision/mAP = 0.0061296835, DetectionBoxes_Precision/mAP (large) = 0.009230337, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.030515013, DetectionBoxes_Precision/mAP@.75IOU = 0.0016030894, DetectionBoxes_Recall/AR@1 = 0.009482072, DetectionBoxes_Recall/AR@10 = 0.06270916, DetectionBoxes_Recall/AR@100 = 0.20294821, DetectionBoxes_Recall/AR@100 (large) = 0.332073, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 5.7989855, Loss/localization_loss = 2.835687, Loss/regularization_loss = 0.30786204, Loss/total_loss = 8.942536, global_step = 3310, learning_rate = 0.004, loss = 8.942536\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3310: training/model.ckpt-3310\n",
            "I0418 13:45:48.359112 139739744683904 estimator.py:2109] Saving 'checkpoint_path' summary for global step 3310: training/model.ckpt-3310\n",
            "INFO:tensorflow:global_step/sec: 2.10158\n",
            "I0418 13:46:04.552484 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 2.10158\n",
            "INFO:tensorflow:loss = 5.6665454, step = 3400 (47.583 sec)\n",
            "I0418 13:46:04.553525 139739744683904 basic_session_run_hooks.py:260] loss = 5.6665454, step = 3400 (47.583 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.65229\n",
            "I0418 13:46:22.244447 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.65229\n",
            "INFO:tensorflow:loss = 4.8844037, step = 3500 (17.692 sec)\n",
            "I0418 13:46:22.245718 139739744683904 basic_session_run_hooks.py:260] loss = 4.8844037, step = 3500 (17.692 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.60877\n",
            "I0418 13:46:40.073684 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.60877\n",
            "INFO:tensorflow:loss = 5.532479, step = 3600 (17.829 sec)\n",
            "I0418 13:46:40.074658 139739744683904 basic_session_run_hooks.py:260] loss = 5.532479, step = 3600 (17.829 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.62973\n",
            "I0418 13:46:57.836503 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.62973\n",
            "INFO:tensorflow:loss = 4.4424024, step = 3700 (17.763 sec)\n",
            "I0418 13:46:57.837327 139739744683904 basic_session_run_hooks.py:260] loss = 4.4424024, step = 3700 (17.763 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.64601\n",
            "I0418 13:47:15.548122 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.64601\n",
            "INFO:tensorflow:loss = 5.707737, step = 3800 (17.712 sec)\n",
            "I0418 13:47:15.549048 139739744683904 basic_session_run_hooks.py:260] loss = 5.707737, step = 3800 (17.712 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.53811\n",
            "I0418 13:47:33.604828 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.53811\n",
            "INFO:tensorflow:loss = 6.732223, step = 3900 (18.057 sec)\n",
            "I0418 13:47:33.605850 139739744683904 basic_session_run_hooks.py:260] loss = 6.732223, step = 3900 (18.057 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.6054\n",
            "I0418 13:47:51.444793 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.6054\n",
            "INFO:tensorflow:loss = 6.322525, step = 4000 (17.840 sec)\n",
            "I0418 13:47:51.445760 139739744683904 basic_session_run_hooks.py:260] loss = 6.322525, step = 4000 (17.840 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.61325\n",
            "I0418 13:48:09.259762 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.61325\n",
            "INFO:tensorflow:loss = 4.906919, step = 4100 (17.815 sec)\n",
            "I0418 13:48:09.260777 139739744683904 basic_session_run_hooks.py:260] loss = 4.906919, step = 4100 (17.815 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.61307\n",
            "I0418 13:48:27.075337 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.61307\n",
            "INFO:tensorflow:loss = 4.941479, step = 4200 (17.816 sec)\n",
            "I0418 13:48:27.076428 139739744683904 basic_session_run_hooks.py:260] loss = 4.941479, step = 4200 (17.816 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.60608\n",
            "I0418 13:48:44.913152 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.60608\n",
            "INFO:tensorflow:loss = 5.2766795, step = 4300 (17.838 sec)\n",
            "I0418 13:48:44.914109 139739744683904 basic_session_run_hooks.py:260] loss = 5.2766795, step = 4300 (17.838 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.60477\n",
            "I0418 13:49:02.755040 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.60477\n",
            "INFO:tensorflow:loss = 6.4987783, step = 4400 (17.842 sec)\n",
            "I0418 13:49:02.755897 139739744683904 basic_session_run_hooks.py:260] loss = 6.4987783, step = 4400 (17.842 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.62715\n",
            "I0418 13:49:20.526034 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.62715\n",
            "INFO:tensorflow:loss = 6.07291, step = 4500 (17.771 sec)\n",
            "I0418 13:49:20.527007 139739744683904 basic_session_run_hooks.py:260] loss = 6.07291, step = 4500 (17.771 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.58233\n",
            "I0418 13:49:38.439690 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.58233\n",
            "INFO:tensorflow:loss = 5.2514715, step = 4600 (17.914 sec)\n",
            "I0418 13:49:38.440584 139739744683904 basic_session_run_hooks.py:260] loss = 5.2514715, step = 4600 (17.914 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.59385\n",
            "I0418 13:49:56.316471 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.59385\n",
            "INFO:tensorflow:loss = 4.9322276, step = 4700 (17.877 sec)\n",
            "I0418 13:49:56.317416 139739744683904 basic_session_run_hooks.py:260] loss = 4.9322276, step = 4700 (17.877 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.60276\n",
            "I0418 13:50:14.164833 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.60276\n",
            "INFO:tensorflow:loss = 4.905326, step = 4800 (17.848 sec)\n",
            "I0418 13:50:14.165855 139739744683904 basic_session_run_hooks.py:260] loss = 4.905326, step = 4800 (17.848 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.57637\n",
            "I0418 13:50:32.097648 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.57637\n",
            "INFO:tensorflow:loss = 5.5258803, step = 4900 (17.933 sec)\n",
            "I0418 13:50:32.098596 139739744683904 basic_session_run_hooks.py:260] loss = 5.5258803, step = 4900 (17.933 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.61077\n",
            "I0418 13:50:49.920507 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.61077\n",
            "INFO:tensorflow:loss = 4.9749274, step = 5000 (17.823 sec)\n",
            "I0418 13:50:49.921533 139739744683904 basic_session_run_hooks.py:260] loss = 4.9749274, step = 5000 (17.823 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.61557\n",
            "I0418 13:51:07.728169 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.61557\n",
            "INFO:tensorflow:loss = 5.4929075, step = 5100 (17.808 sec)\n",
            "I0418 13:51:07.729078 139739744683904 basic_session_run_hooks.py:260] loss = 5.4929075, step = 5100 (17.808 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.59639\n",
            "I0418 13:51:25.596787 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.59639\n",
            "INFO:tensorflow:loss = 5.7273273, step = 5200 (17.869 sec)\n",
            "I0418 13:51:25.597726 139739744683904 basic_session_run_hooks.py:260] loss = 5.7273273, step = 5200 (17.869 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.54572\n",
            "I0418 13:51:43.628700 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.54572\n",
            "INFO:tensorflow:loss = 5.224106, step = 5300 (18.032 sec)\n",
            "I0418 13:51:43.629604 139739744683904 basic_session_run_hooks.py:260] loss = 5.224106, step = 5300 (18.032 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.6136\n",
            "I0418 13:52:01.442580 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.6136\n",
            "INFO:tensorflow:loss = 5.4311604, step = 5400 (17.814 sec)\n",
            "I0418 13:52:01.443545 139739744683904 basic_session_run_hooks.py:260] loss = 5.4311604, step = 5400 (17.814 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.58816\n",
            "I0418 13:52:19.337585 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.58816\n",
            "INFO:tensorflow:loss = 6.2434907, step = 5500 (17.895 sec)\n",
            "I0418 13:52:19.338738 139739744683904 basic_session_run_hooks.py:260] loss = 6.2434907, step = 5500 (17.895 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.57319\n",
            "I0418 13:52:37.280627 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.57319\n",
            "INFO:tensorflow:loss = 5.987352, step = 5600 (17.943 sec)\n",
            "I0418 13:52:37.281578 139739744683904 basic_session_run_hooks.py:260] loss = 5.987352, step = 5600 (17.943 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.57843\n",
            "I0418 13:52:55.206810 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.57843\n",
            "INFO:tensorflow:loss = 5.6782255, step = 5700 (17.926 sec)\n",
            "I0418 13:52:55.207710 139739744683904 basic_session_run_hooks.py:260] loss = 5.6782255, step = 5700 (17.926 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.58556\n",
            "I0418 13:53:13.110144 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.58556\n",
            "INFO:tensorflow:loss = 4.8957863, step = 5800 (17.903 sec)\n",
            "I0418 13:53:13.111175 139739744683904 basic_session_run_hooks.py:260] loss = 4.8957863, step = 5800 (17.903 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.60231\n",
            "I0418 13:53:30.959931 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.60231\n",
            "INFO:tensorflow:loss = 5.4486256, step = 5900 (17.850 sec)\n",
            "I0418 13:53:30.960721 139739744683904 basic_session_run_hooks.py:260] loss = 5.4486256, step = 5900 (17.850 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.58541\n",
            "I0418 13:53:48.863689 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.58541\n",
            "INFO:tensorflow:loss = 5.9227633, step = 6000 (17.904 sec)\n",
            "I0418 13:53:48.864600 139739744683904 basic_session_run_hooks.py:260] loss = 5.9227633, step = 6000 (17.904 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.60449\n",
            "I0418 13:54:06.706547 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.60449\n",
            "INFO:tensorflow:loss = 5.9492564, step = 6100 (17.843 sec)\n",
            "I0418 13:54:06.707436 139739744683904 basic_session_run_hooks.py:260] loss = 5.9492564, step = 6100 (17.843 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.59557\n",
            "I0418 13:54:24.577826 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.59557\n",
            "INFO:tensorflow:loss = 6.2033577, step = 6200 (17.871 sec)\n",
            "I0418 13:54:24.578907 139739744683904 basic_session_run_hooks.py:260] loss = 6.2033577, step = 6200 (17.871 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.57398\n",
            "I0418 13:54:42.518357 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.57398\n",
            "INFO:tensorflow:loss = 5.3424673, step = 6300 (17.940 sec)\n",
            "I0418 13:54:42.519374 139739744683904 basic_session_run_hooks.py:260] loss = 5.3424673, step = 6300 (17.940 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.59252\n",
            "I0418 13:55:00.399345 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.59252\n",
            "INFO:tensorflow:loss = 4.9851174, step = 6400 (17.881 sec)\n",
            "I0418 13:55:00.400268 139739744683904 basic_session_run_hooks.py:260] loss = 4.9851174, step = 6400 (17.881 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.59902\n",
            "I0418 13:55:18.259609 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.59902\n",
            "INFO:tensorflow:loss = 4.978971, step = 6500 (17.860 sec)\n",
            "I0418 13:55:18.260501 139739744683904 basic_session_run_hooks.py:260] loss = 4.978971, step = 6500 (17.860 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 6503 into training/model.ckpt.\n",
            "I0418 13:55:18.602010 139739744683904 basic_session_run_hooks.py:606] Saving checkpoints for 6503 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/fire.record']\n",
            "I0418 13:55:19.765367 139739744683904 dataset_builder.py:162] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/fire.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/fire.record']\n",
            "I0418 13:55:19.773059 139739744683904 dataset_builder.py:79] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/fire.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0418 13:55:19.773199 139739744683904 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f1585ea9250>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W0418 13:55:19.825427 139739744683904 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f1585ea9250>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f1585eaa050> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "W0418 13:55:19.984932 139739744683904 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f1585eaa050> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0418 13:55:20.450815 139739744683904 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 13:55:22.631307 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 13:55:22.660032 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 13:55:22.686769 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 13:55:22.713592 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 13:55:22.741766 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 13:55:22.768813 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0418 13:55:24.065813 139739744683904 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2022-04-18T13:55:24Z\n",
            "I0418 13:55:24.080419 139739744683904 evaluation.py:255] Starting evaluation at 2022-04-18T13:55:24Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0418 13:55:24.465598 139739744683904 monitored_session.py:240] Graph was finalized.\n",
            "2022-04-18 13:55:24.466227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 13:55:24.466709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-04-18 13:55:24.466820: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-04-18 13:55:24.466841: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2022-04-18 13:55:24.466857: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2022-04-18 13:55:24.466887: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2022-04-18 13:55:24.466925: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-04-18 13:55:24.466942: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2022-04-18 13:55:24.466957: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-04-18 13:55:24.467038: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 13:55:24.467473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 13:55:24.467857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2022-04-18 13:55:24.467906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-04-18 13:55:24.467941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2022-04-18 13:55:24.467947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2022-04-18 13:55:24.468055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 13:55:24.468510: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 13:55:24.468929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-6503\n",
            "I0418 13:55:24.469936 139739744683904 saver.py:1284] Restoring parameters from training/model.ckpt-6503\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0418 13:55:25.309300 139739744683904 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0418 13:55:25.432274 139739744683904 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 849 images.\n",
            "I0418 13:55:41.240138 139737318303488 coco_evaluation.py:293] Performing evaluation on 849 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0418 13:55:41.242186 139737318303488 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.06s)\n",
            "I0418 13:55:41.303501 139737318303488 coco_tools.py:138] DONE (t=0.06s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=5.16s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.75s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.020\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.008\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.008\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.088\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.208\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.338\n",
            "INFO:tensorflow:Finished evaluation at 2022-04-18-13:55:47\n",
            "I0418 13:55:47.389674 139739744683904 evaluation.py:275] Finished evaluation at 2022-04-18-13:55:47\n",
            "INFO:tensorflow:Saving dict for global step 6503: DetectionBoxes_Precision/mAP = 0.0047791004, DetectionBoxes_Precision/mAP (large) = 0.0077396054, DetectionBoxes_Precision/mAP (medium) = 0.002237591, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.02002431, DetectionBoxes_Precision/mAP@.75IOU = 0.0007285051, DetectionBoxes_Recall/AR@1 = 0.008366534, DetectionBoxes_Recall/AR@10 = 0.087649405, DetectionBoxes_Recall/AR@100 = 0.20788844, DetectionBoxes_Recall/AR@100 (large) = 0.33794004, DetectionBoxes_Recall/AR@100 (medium) = 0.0044270833, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 5.4996953, Loss/localization_loss = 2.854456, Loss/regularization_loss = 0.30748373, Loss/total_loss = 8.6616335, global_step = 6503, learning_rate = 0.004, loss = 8.6616335\n",
            "I0418 13:55:47.389962 139739744683904 estimator.py:2049] Saving dict for global step 6503: DetectionBoxes_Precision/mAP = 0.0047791004, DetectionBoxes_Precision/mAP (large) = 0.0077396054, DetectionBoxes_Precision/mAP (medium) = 0.002237591, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.02002431, DetectionBoxes_Precision/mAP@.75IOU = 0.0007285051, DetectionBoxes_Recall/AR@1 = 0.008366534, DetectionBoxes_Recall/AR@10 = 0.087649405, DetectionBoxes_Recall/AR@100 = 0.20788844, DetectionBoxes_Recall/AR@100 (large) = 0.33794004, DetectionBoxes_Recall/AR@100 (medium) = 0.0044270833, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 5.4996953, Loss/localization_loss = 2.854456, Loss/regularization_loss = 0.30748373, Loss/total_loss = 8.6616335, global_step = 6503, learning_rate = 0.004, loss = 8.6616335\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6503: training/model.ckpt-6503\n",
            "I0418 13:55:47.392692 139739744683904 estimator.py:2109] Saving 'checkpoint_path' summary for global step 6503: training/model.ckpt-6503\n",
            "INFO:tensorflow:global_step/sec: 2.145\n",
            "I0418 13:56:04.879599 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 2.145\n",
            "INFO:tensorflow:loss = 6.0804567, step = 6600 (46.620 sec)\n",
            "I0418 13:56:04.880519 139739744683904 basic_session_run_hooks.py:260] loss = 6.0804567, step = 6600 (46.620 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.61439\n",
            "I0418 13:56:22.690998 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.61439\n",
            "INFO:tensorflow:loss = 5.186236, step = 6700 (17.811 sec)\n",
            "I0418 13:56:22.691939 139739744683904 basic_session_run_hooks.py:260] loss = 5.186236, step = 6700 (17.811 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.62051\n",
            "I0418 13:56:40.482980 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.62051\n",
            "INFO:tensorflow:loss = 5.53614, step = 6800 (17.792 sec)\n",
            "I0418 13:56:40.483980 139739744683904 basic_session_run_hooks.py:260] loss = 5.53614, step = 6800 (17.792 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.63498\n",
            "I0418 13:56:58.229269 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.63498\n",
            "INFO:tensorflow:loss = 4.5698824, step = 6900 (17.746 sec)\n",
            "I0418 13:56:58.230180 139739744683904 basic_session_run_hooks.py:260] loss = 4.5698824, step = 6900 (17.746 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.59539\n",
            "I0418 13:57:16.101126 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.59539\n",
            "INFO:tensorflow:loss = 6.294456, step = 7000 (17.872 sec)\n",
            "I0418 13:57:16.102074 139739744683904 basic_session_run_hooks.py:260] loss = 6.294456, step = 7000 (17.872 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.5943\n",
            "I0418 13:57:33.976469 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.5943\n",
            "INFO:tensorflow:loss = 5.7396393, step = 7100 (17.875 sec)\n",
            "I0418 13:57:33.977441 139739744683904 basic_session_run_hooks.py:260] loss = 5.7396393, step = 7100 (17.875 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.61658\n",
            "I0418 13:57:51.780912 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.61658\n",
            "INFO:tensorflow:loss = 5.082918, step = 7200 (17.804 sec)\n",
            "I0418 13:57:51.781749 139739744683904 basic_session_run_hooks.py:260] loss = 5.082918, step = 7200 (17.804 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.61653\n",
            "I0418 13:58:09.585489 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.61653\n",
            "INFO:tensorflow:loss = 6.985265, step = 7300 (17.805 sec)\n",
            "I0418 13:58:09.586460 139739744683904 basic_session_run_hooks.py:260] loss = 6.985265, step = 7300 (17.805 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.60607\n",
            "I0418 13:58:27.423309 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.60607\n",
            "INFO:tensorflow:loss = 5.31255, step = 7400 (17.838 sec)\n",
            "I0418 13:58:27.424244 139739744683904 basic_session_run_hooks.py:260] loss = 5.31255, step = 7400 (17.838 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.57569\n",
            "I0418 13:58:45.358296 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.57569\n",
            "INFO:tensorflow:loss = 6.1149645, step = 7500 (17.935 sec)\n",
            "I0418 13:58:45.359452 139739744683904 basic_session_run_hooks.py:260] loss = 6.1149645, step = 7500 (17.935 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.55939\n",
            "I0418 13:59:03.345850 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.55939\n",
            "INFO:tensorflow:loss = 5.850217, step = 7600 (17.987 sec)\n",
            "I0418 13:59:03.346728 139739744683904 basic_session_run_hooks.py:260] loss = 5.850217, step = 7600 (17.987 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.58287\n",
            "I0418 13:59:21.257804 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.58287\n",
            "INFO:tensorflow:loss = 5.0676727, step = 7700 (17.912 sec)\n",
            "I0418 13:59:21.258792 139739744683904 basic_session_run_hooks.py:260] loss = 5.0676727, step = 7700 (17.912 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.6093\n",
            "I0418 13:59:39.085334 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.6093\n",
            "INFO:tensorflow:loss = 4.8264856, step = 7800 (17.828 sec)\n",
            "I0418 13:59:39.086472 139739744683904 basic_session_run_hooks.py:260] loss = 4.8264856, step = 7800 (17.828 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.60515\n",
            "I0418 13:59:56.926124 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.60515\n",
            "INFO:tensorflow:loss = 5.6343784, step = 7900 (17.841 sec)\n",
            "I0418 13:59:56.927053 139739744683904 basic_session_run_hooks.py:260] loss = 5.6343784, step = 7900 (17.841 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.5694\n",
            "I0418 14:00:14.881348 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.5694\n",
            "INFO:tensorflow:loss = 5.8014054, step = 8000 (17.955 sec)\n",
            "I0418 14:00:14.882272 139739744683904 basic_session_run_hooks.py:260] loss = 5.8014054, step = 8000 (17.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.5822\n",
            "I0418 14:00:32.795457 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.5822\n",
            "INFO:tensorflow:loss = 4.529909, step = 8100 (17.914 sec)\n",
            "I0418 14:00:32.796463 139739744683904 basic_session_run_hooks.py:260] loss = 4.529909, step = 8100 (17.914 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.58657\n",
            "I0418 14:00:50.695492 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.58657\n",
            "INFO:tensorflow:loss = 5.6860237, step = 8200 (17.900 sec)\n",
            "I0418 14:00:50.696504 139739744683904 basic_session_run_hooks.py:260] loss = 5.6860237, step = 8200 (17.900 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.57699\n",
            "I0418 14:01:08.626293 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.57699\n",
            "INFO:tensorflow:loss = 5.668309, step = 8300 (17.931 sec)\n",
            "I0418 14:01:08.627215 139739744683904 basic_session_run_hooks.py:260] loss = 5.668309, step = 8300 (17.931 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.5734\n",
            "I0418 14:01:26.568677 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.5734\n",
            "INFO:tensorflow:loss = 5.6122656, step = 8400 (17.942 sec)\n",
            "I0418 14:01:26.569614 139739744683904 basic_session_run_hooks.py:260] loss = 5.6122656, step = 8400 (17.942 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.60954\n",
            "I0418 14:01:44.395465 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.60954\n",
            "INFO:tensorflow:loss = 5.00974, step = 8500 (17.827 sec)\n",
            "I0418 14:01:44.396395 139739744683904 basic_session_run_hooks.py:260] loss = 5.00974, step = 8500 (17.827 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.64906\n",
            "I0418 14:02:02.097506 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.64906\n",
            "INFO:tensorflow:loss = 6.3171005, step = 8600 (17.702 sec)\n",
            "I0418 14:02:02.098483 139739744683904 basic_session_run_hooks.py:260] loss = 6.3171005, step = 8600 (17.702 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.58865\n",
            "I0418 14:02:19.990952 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.58865\n",
            "INFO:tensorflow:loss = 6.590011, step = 8700 (17.893 sec)\n",
            "I0418 14:02:19.991888 139739744683904 basic_session_run_hooks.py:260] loss = 6.590011, step = 8700 (17.893 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.59183\n",
            "I0418 14:02:37.874184 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.59183\n",
            "INFO:tensorflow:loss = 5.5915294, step = 8800 (17.883 sec)\n",
            "I0418 14:02:37.875150 139739744683904 basic_session_run_hooks.py:260] loss = 5.5915294, step = 8800 (17.883 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.55672\n",
            "I0418 14:02:55.870410 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.55672\n",
            "INFO:tensorflow:loss = 5.5273356, step = 8900 (17.996 sec)\n",
            "I0418 14:02:55.871413 139739744683904 basic_session_run_hooks.py:260] loss = 5.5273356, step = 8900 (17.996 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.55574\n",
            "I0418 14:03:13.869798 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.55574\n",
            "INFO:tensorflow:loss = 5.9038396, step = 9000 (17.999 sec)\n",
            "I0418 14:03:13.870646 139739744683904 basic_session_run_hooks.py:260] loss = 5.9038396, step = 9000 (17.999 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.56392\n",
            "I0418 14:03:31.842737 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.56392\n",
            "INFO:tensorflow:loss = 5.701408, step = 9100 (17.973 sec)\n",
            "I0418 14:03:31.843786 139739744683904 basic_session_run_hooks.py:260] loss = 5.701408, step = 9100 (17.973 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.59818\n",
            "I0418 14:03:49.705674 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.59818\n",
            "INFO:tensorflow:loss = 5.19329, step = 9200 (17.863 sec)\n",
            "I0418 14:03:49.706578 139739744683904 basic_session_run_hooks.py:260] loss = 5.19329, step = 9200 (17.863 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.58466\n",
            "I0418 14:04:07.611849 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.58466\n",
            "INFO:tensorflow:loss = 6.137845, step = 9300 (17.906 sec)\n",
            "I0418 14:04:07.612800 139739744683904 basic_session_run_hooks.py:260] loss = 6.137845, step = 9300 (17.906 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.57218\n",
            "I0418 14:04:25.558145 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.57218\n",
            "INFO:tensorflow:loss = 5.4595165, step = 9400 (17.946 sec)\n",
            "I0418 14:04:25.558923 139739744683904 basic_session_run_hooks.py:260] loss = 5.4595165, step = 9400 (17.946 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.60672\n",
            "I0418 14:04:43.393918 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.60672\n",
            "INFO:tensorflow:loss = 5.1607666, step = 9500 (17.836 sec)\n",
            "I0418 14:04:43.394828 139739744683904 basic_session_run_hooks.py:260] loss = 5.1607666, step = 9500 (17.836 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.60594\n",
            "I0418 14:05:01.232111 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.60594\n",
            "INFO:tensorflow:loss = 5.5290194, step = 9600 (17.838 sec)\n",
            "I0418 14:05:01.233070 139739744683904 basic_session_run_hooks.py:260] loss = 5.5290194, step = 9600 (17.838 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 9699 into training/model.ckpt.\n",
            "I0418 14:05:18.778009 139739744683904 basic_session_run_hooks.py:606] Saving checkpoints for 9699 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/fire.record']\n",
            "I0418 14:05:19.968231 139739744683904 dataset_builder.py:162] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/fire.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/fire.record']\n",
            "I0418 14:05:19.977440 139739744683904 dataset_builder.py:79] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/fire.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0418 14:05:19.977566 139739744683904 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f16a85ad450>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W0418 14:05:20.028484 139739744683904 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f16a85ad450>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f1588b88050> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "W0418 14:05:20.191849 139739744683904 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f1588b88050> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0418 14:05:20.662441 139739744683904 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 14:05:22.518969 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 14:05:22.546328 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 14:05:22.572886 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 14:05:22.599356 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 14:05:22.626121 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 14:05:22.654433 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0418 14:05:23.902478 139739744683904 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2022-04-18T14:05:23Z\n",
            "I0418 14:05:23.916866 139739744683904 evaluation.py:255] Starting evaluation at 2022-04-18T14:05:23Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0418 14:05:24.283368 139739744683904 monitored_session.py:240] Graph was finalized.\n",
            "2022-04-18 14:05:24.283996: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:05:24.284475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-04-18 14:05:24.284576: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-04-18 14:05:24.284596: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2022-04-18 14:05:24.284611: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2022-04-18 14:05:24.284626: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2022-04-18 14:05:24.284641: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-04-18 14:05:24.284655: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2022-04-18 14:05:24.284677: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-04-18 14:05:24.284769: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:05:24.285269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:05:24.285658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2022-04-18 14:05:24.285701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-04-18 14:05:24.285718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2022-04-18 14:05:24.285725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2022-04-18 14:05:24.285805: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:05:24.286238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:05:24.286629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-9699\n",
            "I0418 14:05:24.287577 139739744683904 saver.py:1284] Restoring parameters from training/model.ckpt-9699\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0418 14:05:25.130465 139739744683904 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0418 14:05:25.245071 139739744683904 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 849 images.\n",
            "I0418 14:05:40.796297 139735771301632 coco_evaluation.py:293] Performing evaluation on 849 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0418 14:05:40.800827 139735771301632 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.07s)\n",
            "I0418 14:05:40.866585 139735771301632 coco_tools.py:138] DONE (t=0.07s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=5.21s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.77s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.020\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.087\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.016\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.029\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.029\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.145\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.278\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.032\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.131\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.385\n",
            "INFO:tensorflow:Finished evaluation at 2022-04-18-14:05:47\n",
            "I0418 14:05:47.025063 139739744683904 evaluation.py:275] Finished evaluation at 2022-04-18-14:05:47\n",
            "INFO:tensorflow:Saving dict for global step 9699: DetectionBoxes_Precision/mAP = 0.019753996, DetectionBoxes_Precision/mAP (large) = 0.029455973, DetectionBoxes_Precision/mAP (medium) = 0.016158147, DetectionBoxes_Precision/mAP (small) = 5.990976e-05, DetectionBoxes_Precision/mAP@.50IOU = 0.087035485, DetectionBoxes_Precision/mAP@.75IOU = 0.0013410902, DetectionBoxes_Recall/AR@1 = 0.029243028, DetectionBoxes_Recall/AR@10 = 0.14549801, DetectionBoxes_Recall/AR@100 = 0.2779283, DetectionBoxes_Recall/AR@100 (large) = 0.38474578, DetectionBoxes_Recall/AR@100 (medium) = 0.13125, DetectionBoxes_Recall/AR@100 (small) = 0.03173077, Loss/classification_loss = 5.200428, Loss/localization_loss = 2.1250288, Loss/regularization_loss = 0.3072964, Loss/total_loss = 7.6327605, global_step = 9699, learning_rate = 0.004, loss = 7.6327605\n",
            "I0418 14:05:47.025323 139739744683904 estimator.py:2049] Saving dict for global step 9699: DetectionBoxes_Precision/mAP = 0.019753996, DetectionBoxes_Precision/mAP (large) = 0.029455973, DetectionBoxes_Precision/mAP (medium) = 0.016158147, DetectionBoxes_Precision/mAP (small) = 5.990976e-05, DetectionBoxes_Precision/mAP@.50IOU = 0.087035485, DetectionBoxes_Precision/mAP@.75IOU = 0.0013410902, DetectionBoxes_Recall/AR@1 = 0.029243028, DetectionBoxes_Recall/AR@10 = 0.14549801, DetectionBoxes_Recall/AR@100 = 0.2779283, DetectionBoxes_Recall/AR@100 (large) = 0.38474578, DetectionBoxes_Recall/AR@100 (medium) = 0.13125, DetectionBoxes_Recall/AR@100 (small) = 0.03173077, Loss/classification_loss = 5.200428, Loss/localization_loss = 2.1250288, Loss/regularization_loss = 0.3072964, Loss/total_loss = 7.6327605, global_step = 9699, learning_rate = 0.004, loss = 7.6327605\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 9699: training/model.ckpt-9699\n",
            "I0418 14:05:47.028743 139739744683904 estimator.py:2109] Saving 'checkpoint_path' summary for global step 9699: training/model.ckpt-9699\n",
            "INFO:tensorflow:global_step/sec: 2.16199\n",
            "I0418 14:05:47.485907 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 2.16199\n",
            "INFO:tensorflow:loss = 4.7726727, step = 9700 (46.254 sec)\n",
            "I0418 14:05:47.486785 139739744683904 basic_session_run_hooks.py:260] loss = 4.7726727, step = 9700 (46.254 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.65485\n",
            "I0418 14:06:05.169820 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.65485\n",
            "INFO:tensorflow:loss = 4.640043, step = 9800 (17.684 sec)\n",
            "I0418 14:06:05.170692 139739744683904 basic_session_run_hooks.py:260] loss = 4.640043, step = 9800 (17.684 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.62558\n",
            "I0418 14:06:22.945762 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.62558\n",
            "INFO:tensorflow:loss = 4.533974, step = 9900 (17.776 sec)\n",
            "I0418 14:06:22.946736 139739744683904 basic_session_run_hooks.py:260] loss = 4.533974, step = 9900 (17.776 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.62101\n",
            "I0418 14:06:40.736192 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.62101\n",
            "INFO:tensorflow:loss = 4.946773, step = 10000 (17.790 sec)\n",
            "I0418 14:06:40.737176 139739744683904 basic_session_run_hooks.py:260] loss = 4.946773, step = 10000 (17.790 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.65564\n",
            "I0418 14:06:58.417637 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.65564\n",
            "INFO:tensorflow:loss = 5.509438, step = 10100 (17.681 sec)\n",
            "I0418 14:06:58.418668 139739744683904 basic_session_run_hooks.py:260] loss = 5.509438, step = 10100 (17.681 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.58412\n",
            "I0418 14:07:16.325566 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.58412\n",
            "INFO:tensorflow:loss = 4.836013, step = 10200 (17.908 sec)\n",
            "I0418 14:07:16.326513 139739744683904 basic_session_run_hooks.py:260] loss = 4.836013, step = 10200 (17.908 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.62107\n",
            "I0418 14:07:34.115780 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.62107\n",
            "INFO:tensorflow:loss = 5.0700316, step = 10300 (17.790 sec)\n",
            "I0418 14:07:34.116789 139739744683904 basic_session_run_hooks.py:260] loss = 5.0700316, step = 10300 (17.790 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.60089\n",
            "I0418 14:07:51.970091 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.60089\n",
            "INFO:tensorflow:loss = 5.24555, step = 10400 (17.854 sec)\n",
            "I0418 14:07:51.971049 139739744683904 basic_session_run_hooks.py:260] loss = 5.24555, step = 10400 (17.854 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.63125\n",
            "I0418 14:08:09.728141 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.63125\n",
            "INFO:tensorflow:loss = 6.4339437, step = 10500 (17.758 sec)\n",
            "I0418 14:08:09.728995 139739744683904 basic_session_run_hooks.py:260] loss = 6.4339437, step = 10500 (17.758 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.5707\n",
            "I0418 14:08:27.679243 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.5707\n",
            "INFO:tensorflow:loss = 7.2258525, step = 10600 (17.951 sec)\n",
            "I0418 14:08:27.680151 139739744683904 basic_session_run_hooks.py:260] loss = 7.2258525, step = 10600 (17.951 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.61515\n",
            "I0418 14:08:45.488178 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.61515\n",
            "INFO:tensorflow:loss = 4.9384756, step = 10700 (17.809 sec)\n",
            "I0418 14:08:45.489071 139739744683904 basic_session_run_hooks.py:260] loss = 4.9384756, step = 10700 (17.809 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.59849\n",
            "I0418 14:09:03.350143 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.59849\n",
            "INFO:tensorflow:loss = 6.214746, step = 10800 (17.862 sec)\n",
            "I0418 14:09:03.351182 139739744683904 basic_session_run_hooks.py:260] loss = 6.214746, step = 10800 (17.862 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.60329\n",
            "I0418 14:09:21.196782 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.60329\n",
            "INFO:tensorflow:loss = 4.9009886, step = 10900 (17.847 sec)\n",
            "I0418 14:09:21.197800 139739744683904 basic_session_run_hooks.py:260] loss = 4.9009886, step = 10900 (17.847 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.60235\n",
            "I0418 14:09:39.046425 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.60235\n",
            "INFO:tensorflow:loss = 6.7941103, step = 11000 (17.850 sec)\n",
            "I0418 14:09:39.047353 139739744683904 basic_session_run_hooks.py:260] loss = 6.7941103, step = 11000 (17.850 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.60665\n",
            "I0418 14:09:56.882393 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.60665\n",
            "INFO:tensorflow:loss = 4.482047, step = 11100 (17.836 sec)\n",
            "I0418 14:09:56.883188 139739744683904 basic_session_run_hooks.py:260] loss = 4.482047, step = 11100 (17.836 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.57921\n",
            "I0418 14:10:14.806079 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.57921\n",
            "INFO:tensorflow:loss = 5.0715322, step = 11200 (17.924 sec)\n",
            "I0418 14:10:14.807032 139739744683904 basic_session_run_hooks.py:260] loss = 5.0715322, step = 11200 (17.924 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.60658\n",
            "I0418 14:10:32.642269 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.60658\n",
            "INFO:tensorflow:loss = 5.6272316, step = 11300 (17.836 sec)\n",
            "I0418 14:10:32.643278 139739744683904 basic_session_run_hooks.py:260] loss = 5.6272316, step = 11300 (17.836 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.58741\n",
            "I0418 14:10:50.539630 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.58741\n",
            "INFO:tensorflow:loss = 5.562994, step = 11400 (17.897 sec)\n",
            "I0418 14:10:50.540660 139739744683904 basic_session_run_hooks.py:260] loss = 5.562994, step = 11400 (17.897 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.58702\n",
            "I0418 14:11:08.438227 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.58702\n",
            "INFO:tensorflow:loss = 5.953074, step = 11500 (17.898 sec)\n",
            "I0418 14:11:08.439122 139739744683904 basic_session_run_hooks.py:260] loss = 5.953074, step = 11500 (17.898 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.60849\n",
            "I0418 14:11:26.268338 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.60849\n",
            "INFO:tensorflow:loss = 4.8862033, step = 11600 (17.830 sec)\n",
            "I0418 14:11:26.269412 139739744683904 basic_session_run_hooks.py:260] loss = 4.8862033, step = 11600 (17.830 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.59456\n",
            "I0418 14:11:44.142857 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.59456\n",
            "INFO:tensorflow:loss = 4.941333, step = 11700 (17.874 sec)\n",
            "I0418 14:11:44.143775 139739744683904 basic_session_run_hooks.py:260] loss = 4.941333, step = 11700 (17.874 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.58874\n",
            "I0418 14:12:02.035993 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.58874\n",
            "INFO:tensorflow:loss = 4.9028373, step = 11800 (17.893 sec)\n",
            "I0418 14:12:02.036809 139739744683904 basic_session_run_hooks.py:260] loss = 4.9028373, step = 11800 (17.893 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.57061\n",
            "I0418 14:12:19.987349 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.57061\n",
            "INFO:tensorflow:loss = 4.685934, step = 11900 (17.951 sec)\n",
            "I0418 14:12:19.988269 139739744683904 basic_session_run_hooks.py:260] loss = 4.685934, step = 11900 (17.951 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.58144\n",
            "I0418 14:12:37.903918 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.58144\n",
            "INFO:tensorflow:loss = 4.95609, step = 12000 (17.917 sec)\n",
            "I0418 14:12:37.904798 139739744683904 basic_session_run_hooks.py:260] loss = 4.95609, step = 12000 (17.917 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.59689\n",
            "I0418 14:12:55.770953 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.59689\n",
            "INFO:tensorflow:loss = 5.4385943, step = 12100 (17.867 sec)\n",
            "I0418 14:12:55.771778 139739744683904 basic_session_run_hooks.py:260] loss = 5.4385943, step = 12100 (17.867 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.5983\n",
            "I0418 14:13:13.633492 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.5983\n",
            "INFO:tensorflow:loss = 4.5817375, step = 12200 (17.862 sec)\n",
            "I0418 14:13:13.634263 139739744683904 basic_session_run_hooks.py:260] loss = 4.5817375, step = 12200 (17.862 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.58589\n",
            "I0418 14:13:31.535730 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.58589\n",
            "INFO:tensorflow:loss = 5.1378183, step = 12300 (17.902 sec)\n",
            "I0418 14:13:31.536754 139739744683904 basic_session_run_hooks.py:260] loss = 5.1378183, step = 12300 (17.902 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.58176\n",
            "I0418 14:13:49.451214 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.58176\n",
            "INFO:tensorflow:loss = 5.7940254, step = 12400 (17.915 sec)\n",
            "I0418 14:13:49.452135 139739744683904 basic_session_run_hooks.py:260] loss = 5.7940254, step = 12400 (17.915 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.5926\n",
            "I0418 14:14:07.332002 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.5926\n",
            "INFO:tensorflow:loss = 4.4159546, step = 12500 (17.881 sec)\n",
            "I0418 14:14:07.332867 139739744683904 basic_session_run_hooks.py:260] loss = 4.4159546, step = 12500 (17.881 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.55208\n",
            "I0418 14:14:25.343257 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.55208\n",
            "INFO:tensorflow:loss = 4.7523246, step = 12600 (18.011 sec)\n",
            "I0418 14:14:25.344199 139739744683904 basic_session_run_hooks.py:260] loss = 4.7523246, step = 12600 (18.011 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.58608\n",
            "I0418 14:14:43.244915 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.58608\n",
            "INFO:tensorflow:loss = 4.461179, step = 12700 (17.902 sec)\n",
            "I0418 14:14:43.245912 139739744683904 basic_session_run_hooks.py:260] loss = 4.461179, step = 12700 (17.902 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.56018\n",
            "I0418 14:15:01.229967 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.56018\n",
            "INFO:tensorflow:loss = 4.8443904, step = 12800 (17.985 sec)\n",
            "I0418 14:15:01.230983 139739744683904 basic_session_run_hooks.py:260] loss = 4.8443904, step = 12800 (17.985 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 12900 into training/model.ckpt.\n",
            "I0418 14:15:18.953769 139739744683904 basic_session_run_hooks.py:606] Saving checkpoints for 12900 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/fire.record']\n",
            "I0418 14:15:20.155241 139739744683904 dataset_builder.py:162] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/fire.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/fire.record']\n",
            "I0418 14:15:20.162555 139739744683904 dataset_builder.py:79] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/fire.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0418 14:15:20.162676 139739744683904 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f1588bdfad0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W0418 14:15:20.214305 139739744683904 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f1588bdfad0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f15888580e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "W0418 14:15:20.376807 139739744683904 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f15888580e0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0418 14:15:20.845958 139739744683904 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 14:15:23.006020 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 14:15:23.033994 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 14:15:23.060992 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 14:15:23.087902 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 14:15:23.115280 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 14:15:23.142081 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0418 14:15:24.367660 139739744683904 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2022-04-18T14:15:24Z\n",
            "I0418 14:15:24.383428 139739744683904 evaluation.py:255] Starting evaluation at 2022-04-18T14:15:24Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0418 14:15:24.755173 139739744683904 monitored_session.py:240] Graph was finalized.\n",
            "2022-04-18 14:15:24.755786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:15:24.756278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-04-18 14:15:24.756372: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-04-18 14:15:24.756392: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2022-04-18 14:15:24.756407: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2022-04-18 14:15:24.756421: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2022-04-18 14:15:24.756439: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-04-18 14:15:24.756456: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2022-04-18 14:15:24.756473: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-04-18 14:15:24.756544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:15:24.757019: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:15:24.757407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2022-04-18 14:15:24.757544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-04-18 14:15:24.757555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2022-04-18 14:15:24.757561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2022-04-18 14:15:24.757642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:15:24.758085: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:15:24.758479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-12900\n",
            "I0418 14:15:24.759523 139739744683904 saver.py:1284] Restoring parameters from training/model.ckpt-12900\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0418 14:15:25.621090 139739744683904 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0418 14:15:25.750012 139739744683904 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 849 images.\n",
            "I0418 14:15:41.709410 139737318303488 coco_evaluation.py:293] Performing evaluation on 849 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0418 14:15:41.713096 139737318303488 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.07s)\n",
            "I0418 14:15:41.779206 139737318303488 coco_tools.py:138] DONE (t=0.07s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=4.92s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.79s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.214\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.494\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.152\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.070\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.313\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.238\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.344\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.415\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.066\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.255\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.543\n",
            "INFO:tensorflow:Finished evaluation at 2022-04-18-14:15:47\n",
            "I0418 14:15:47.665848 139739744683904 evaluation.py:275] Finished evaluation at 2022-04-18-14:15:47\n",
            "INFO:tensorflow:Saving dict for global step 12900: DetectionBoxes_Precision/mAP = 0.21434134, DetectionBoxes_Precision/mAP (large) = 0.31259504, DetectionBoxes_Precision/mAP (medium) = 0.070099644, DetectionBoxes_Precision/mAP (small) = 0.0019136824, DetectionBoxes_Precision/mAP@.50IOU = 0.4938341, DetectionBoxes_Precision/mAP@.75IOU = 0.15205981, DetectionBoxes_Recall/AR@1 = 0.23784861, DetectionBoxes_Recall/AR@10 = 0.34406376, DetectionBoxes_Recall/AR@100 = 0.41545817, DetectionBoxes_Recall/AR@100 (large) = 0.5428944, DetectionBoxes_Recall/AR@100 (medium) = 0.25546876, DetectionBoxes_Recall/AR@100 (small) = 0.06634615, Loss/classification_loss = 4.2959833, Loss/localization_loss = 1.358298, Loss/regularization_loss = 0.30732676, Loss/total_loss = 5.9616117, global_step = 12900, learning_rate = 0.004, loss = 5.9616117\n",
            "I0418 14:15:47.666121 139739744683904 estimator.py:2049] Saving dict for global step 12900: DetectionBoxes_Precision/mAP = 0.21434134, DetectionBoxes_Precision/mAP (large) = 0.31259504, DetectionBoxes_Precision/mAP (medium) = 0.070099644, DetectionBoxes_Precision/mAP (small) = 0.0019136824, DetectionBoxes_Precision/mAP@.50IOU = 0.4938341, DetectionBoxes_Precision/mAP@.75IOU = 0.15205981, DetectionBoxes_Recall/AR@1 = 0.23784861, DetectionBoxes_Recall/AR@10 = 0.34406376, DetectionBoxes_Recall/AR@100 = 0.41545817, DetectionBoxes_Recall/AR@100 (large) = 0.5428944, DetectionBoxes_Recall/AR@100 (medium) = 0.25546876, DetectionBoxes_Recall/AR@100 (small) = 0.06634615, Loss/classification_loss = 4.2959833, Loss/localization_loss = 1.358298, Loss/regularization_loss = 0.30732676, Loss/total_loss = 5.9616117, global_step = 12900, learning_rate = 0.004, loss = 5.9616117\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12900: training/model.ckpt-12900\n",
            "I0418 14:15:47.668703 139739744683904 estimator.py:2109] Saving 'checkpoint_path' summary for global step 12900: training/model.ckpt-12900\n",
            "INFO:tensorflow:global_step/sec: 2.14125\n",
            "I0418 14:15:47.931689 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 2.14125\n",
            "INFO:tensorflow:loss = 5.4959183, step = 12900 (46.702 sec)\n",
            "I0418 14:15:47.932800 139739744683904 basic_session_run_hooks.py:260] loss = 5.4959183, step = 12900 (46.702 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.607\n",
            "I0418 14:16:05.766539 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.607\n",
            "INFO:tensorflow:loss = 4.3641434, step = 13000 (17.835 sec)\n",
            "I0418 14:16:05.767442 139739744683904 basic_session_run_hooks.py:260] loss = 4.3641434, step = 13000 (17.835 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.61663\n",
            "I0418 14:16:23.570774 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.61663\n",
            "INFO:tensorflow:loss = 5.51968, step = 13100 (17.804 sec)\n",
            "I0418 14:16:23.571866 139739744683904 basic_session_run_hooks.py:260] loss = 5.51968, step = 13100 (17.804 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.65622\n",
            "I0418 14:16:41.250410 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.65622\n",
            "INFO:tensorflow:loss = 5.7261534, step = 13200 (17.679 sec)\n",
            "I0418 14:16:41.251285 139739744683904 basic_session_run_hooks.py:260] loss = 5.7261534, step = 13200 (17.679 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.57658\n",
            "I0418 14:16:59.182559 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.57658\n",
            "INFO:tensorflow:loss = 4.187527, step = 13300 (17.932 sec)\n",
            "I0418 14:16:59.183546 139739744683904 basic_session_run_hooks.py:260] loss = 4.187527, step = 13300 (17.932 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.59603\n",
            "I0418 14:17:17.052373 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.59603\n",
            "INFO:tensorflow:loss = 6.129176, step = 13400 (17.870 sec)\n",
            "I0418 14:17:17.053520 139739744683904 basic_session_run_hooks.py:260] loss = 6.129176, step = 13400 (17.870 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.6261\n",
            "I0418 14:17:34.826660 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.6261\n",
            "INFO:tensorflow:loss = 5.927483, step = 13500 (17.774 sec)\n",
            "I0418 14:17:34.827645 139739744683904 basic_session_run_hooks.py:260] loss = 5.927483, step = 13500 (17.774 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.59436\n",
            "I0418 14:17:52.701811 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.59436\n",
            "INFO:tensorflow:loss = 4.4895177, step = 13600 (17.875 sec)\n",
            "I0418 14:17:52.702801 139739744683904 basic_session_run_hooks.py:260] loss = 4.4895177, step = 13600 (17.875 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.58161\n",
            "I0418 14:18:10.617801 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.58161\n",
            "INFO:tensorflow:loss = 4.977344, step = 13700 (17.916 sec)\n",
            "I0418 14:18:10.618815 139739744683904 basic_session_run_hooks.py:260] loss = 4.977344, step = 13700 (17.916 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.56637\n",
            "I0418 14:18:28.582859 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.56637\n",
            "INFO:tensorflow:loss = 5.440274, step = 13800 (17.965 sec)\n",
            "I0418 14:18:28.583650 139739744683904 basic_session_run_hooks.py:260] loss = 5.440274, step = 13800 (17.965 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.57225\n",
            "I0418 14:18:46.528922 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.57225\n",
            "INFO:tensorflow:loss = 5.289992, step = 13900 (17.946 sec)\n",
            "I0418 14:18:46.529848 139739744683904 basic_session_run_hooks.py:260] loss = 5.289992, step = 13900 (17.946 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.58617\n",
            "I0418 14:19:04.430269 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.58617\n",
            "INFO:tensorflow:loss = 5.371039, step = 14000 (17.901 sec)\n",
            "I0418 14:19:04.431072 139739744683904 basic_session_run_hooks.py:260] loss = 5.371039, step = 14000 (17.901 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.57472\n",
            "I0418 14:19:22.368386 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.57472\n",
            "INFO:tensorflow:loss = 4.5629435, step = 14100 (17.938 sec)\n",
            "I0418 14:19:22.369215 139739744683904 basic_session_run_hooks.py:260] loss = 4.5629435, step = 14100 (17.938 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.61189\n",
            "I0418 14:19:40.187705 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.61189\n",
            "INFO:tensorflow:loss = 5.7636876, step = 14200 (17.819 sec)\n",
            "I0418 14:19:40.188711 139739744683904 basic_session_run_hooks.py:260] loss = 5.7636876, step = 14200 (17.819 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.59682\n",
            "I0418 14:19:58.055007 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.59682\n",
            "INFO:tensorflow:loss = 5.647031, step = 14300 (17.867 sec)\n",
            "I0418 14:19:58.056064 139739744683904 basic_session_run_hooks.py:260] loss = 5.647031, step = 14300 (17.867 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.55497\n",
            "I0418 14:20:16.056909 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.55497\n",
            "INFO:tensorflow:loss = 5.3545866, step = 14400 (18.002 sec)\n",
            "I0418 14:20:16.057896 139739744683904 basic_session_run_hooks.py:260] loss = 5.3545866, step = 14400 (18.002 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.61072\n",
            "I0418 14:20:33.879938 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.61072\n",
            "INFO:tensorflow:loss = 6.97435, step = 14500 (17.823 sec)\n",
            "I0418 14:20:33.880990 139739744683904 basic_session_run_hooks.py:260] loss = 6.97435, step = 14500 (17.823 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.58661\n",
            "I0418 14:20:51.779881 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.58661\n",
            "INFO:tensorflow:loss = 5.4310007, step = 14600 (17.900 sec)\n",
            "I0418 14:20:51.780802 139739744683904 basic_session_run_hooks.py:260] loss = 5.4310007, step = 14600 (17.900 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.61165\n",
            "I0418 14:21:09.599963 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.61165\n",
            "INFO:tensorflow:loss = 5.120582, step = 14700 (17.820 sec)\n",
            "I0418 14:21:09.600939 139739744683904 basic_session_run_hooks.py:260] loss = 5.120582, step = 14700 (17.820 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.54202\n",
            "I0418 14:21:27.643934 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.54202\n",
            "INFO:tensorflow:loss = 4.626546, step = 14800 (18.044 sec)\n",
            "I0418 14:21:27.644685 139739744683904 basic_session_run_hooks.py:260] loss = 4.626546, step = 14800 (18.044 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.58791\n",
            "I0418 14:21:45.539715 139739744683904 basic_session_run_hooks.py:692] global_step/sec: 5.58791\n",
            "INFO:tensorflow:loss = 5.4914517, step = 14900 (17.896 sec)\n",
            "I0418 14:21:45.540637 139739744683904 basic_session_run_hooks.py:260] loss = 5.4914517, step = 14900 (17.896 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 15000 into training/model.ckpt.\n",
            "I0418 14:22:03.308833 139739744683904 basic_session_run_hooks.py:606] Saving checkpoints for 15000 into training/model.ckpt.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "W0418 14:22:03.395068 139739744683904 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "I0418 14:22:04.499180 139739744683904 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/fire.record']\n",
            "I0418 14:22:04.517752 139739744683904 dataset_builder.py:162] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test/fire.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/fire.record']\n",
            "I0418 14:22:04.525131 139739744683904 dataset_builder.py:79] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test/fire.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0418 14:22:04.525253 139739744683904 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f16a81bbd50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "W0418 14:22:04.576142 139739744683904 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f16a81bbd50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f1589096050> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "W0418 14:22:04.743785 139739744683904 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7f1589096050> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0418 14:22:05.210704 139739744683904 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 14:22:07.071080 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 14:22:07.098486 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 14:22:07.125469 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 14:22:07.152018 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 14:22:07.179064 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 14:22:07.205669 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0418 14:22:08.410133 139739744683904 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2022-04-18T14:22:08Z\n",
            "I0418 14:22:08.424494 139739744683904 evaluation.py:255] Starting evaluation at 2022-04-18T14:22:08Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0418 14:22:08.787015 139739744683904 monitored_session.py:240] Graph was finalized.\n",
            "2022-04-18 14:22:08.787718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:22:08.788406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-04-18 14:22:08.788542: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-04-18 14:22:08.788577: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2022-04-18 14:22:08.788618: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2022-04-18 14:22:08.788651: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2022-04-18 14:22:08.788678: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-04-18 14:22:08.788702: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2022-04-18 14:22:08.788726: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-04-18 14:22:08.788834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:22:08.789508: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:22:08.790099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2022-04-18 14:22:08.790155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-04-18 14:22:08.790173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2022-04-18 14:22:08.790187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2022-04-18 14:22:08.790314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:22:08.790990: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:22:08.791587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-15000\n",
            "I0418 14:22:08.792454 139739744683904 saver.py:1284] Restoring parameters from training/model.ckpt-15000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0418 14:22:09.608507 139739744683904 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0418 14:22:09.728082 139739744683904 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 849 images.\n",
            "I0418 14:22:26.268052 139737318303488 coco_evaluation.py:293] Performing evaluation on 849 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0418 14:22:26.271984 139737318303488 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.07s)\n",
            "I0418 14:22:26.338179 139737318303488 coco_tools.py:138] DONE (t=0.07s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=4.96s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.72s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.238\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.558\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.162\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.084\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.340\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.254\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.381\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.442\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.068\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.293\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.566\n",
            "INFO:tensorflow:Finished evaluation at 2022-04-18-14:22:32\n",
            "I0418 14:22:32.190860 139739744683904 evaluation.py:275] Finished evaluation at 2022-04-18-14:22:32\n",
            "INFO:tensorflow:Saving dict for global step 15000: DetectionBoxes_Precision/mAP = 0.23830673, DetectionBoxes_Precision/mAP (large) = 0.3399011, DetectionBoxes_Precision/mAP (medium) = 0.083683945, DetectionBoxes_Precision/mAP (small) = 0.003189167, DetectionBoxes_Precision/mAP@.50IOU = 0.55754435, DetectionBoxes_Precision/mAP@.75IOU = 0.16172808, DetectionBoxes_Recall/AR@1 = 0.25378487, DetectionBoxes_Recall/AR@10 = 0.38111553, DetectionBoxes_Recall/AR@100 = 0.44151396, DetectionBoxes_Recall/AR@100 (large) = 0.5662321, DetectionBoxes_Recall/AR@100 (medium) = 0.29348958, DetectionBoxes_Recall/AR@100 (small) = 0.06826923, Loss/classification_loss = 4.237311, Loss/localization_loss = 1.2895283, Loss/regularization_loss = 0.3074942, Loss/total_loss = 5.834327, global_step = 15000, learning_rate = 0.004, loss = 5.834327\n",
            "I0418 14:22:32.191121 139739744683904 estimator.py:2049] Saving dict for global step 15000: DetectionBoxes_Precision/mAP = 0.23830673, DetectionBoxes_Precision/mAP (large) = 0.3399011, DetectionBoxes_Precision/mAP (medium) = 0.083683945, DetectionBoxes_Precision/mAP (small) = 0.003189167, DetectionBoxes_Precision/mAP@.50IOU = 0.55754435, DetectionBoxes_Precision/mAP@.75IOU = 0.16172808, DetectionBoxes_Recall/AR@1 = 0.25378487, DetectionBoxes_Recall/AR@10 = 0.38111553, DetectionBoxes_Recall/AR@100 = 0.44151396, DetectionBoxes_Recall/AR@100 (large) = 0.5662321, DetectionBoxes_Recall/AR@100 (medium) = 0.29348958, DetectionBoxes_Recall/AR@100 (small) = 0.06826923, Loss/classification_loss = 4.237311, Loss/localization_loss = 1.2895283, Loss/regularization_loss = 0.3074942, Loss/total_loss = 5.834327, global_step = 15000, learning_rate = 0.004, loss = 5.834327\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 15000: training/model.ckpt-15000\n",
            "I0418 14:22:32.193666 139739744683904 estimator.py:2109] Saving 'checkpoint_path' summary for global step 15000: training/model.ckpt-15000\n",
            "INFO:tensorflow:Performing the final export in the end of training.\n",
            "I0418 14:22:32.194360 139739744683904 exporter.py:410] Performing the final export in the end of training.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0418 14:22:32.430272 139739744683904 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 14:22:34.553683 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 14:22:34.585583 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 14:22:34.614421 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 14:22:34.642802 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 14:22:34.671430 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 14:22:34.699646 139739744683904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0418 14:22:35.310427 139739744683904 estimator.py:1150] Done calling model_fn.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0418 14:22:35.310702 139739744683904 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "I0418 14:22:35.311258 139739744683904 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "I0418 14:22:35.311362 139739744683904 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "I0418 14:22:35.311440 139739744683904 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "I0418 14:22:35.311510 139739744683904 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "I0418 14:22:35.311576 139739744683904 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n",
            "2022-04-18 14:22:35.312094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:22:35.312566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-04-18 14:22:35.312682: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-04-18 14:22:35.312710: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2022-04-18 14:22:35.312737: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2022-04-18 14:22:35.312760: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2022-04-18 14:22:35.312783: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-04-18 14:22:35.312810: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2022-04-18 14:22:35.312835: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-04-18 14:22:35.312952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:22:35.313411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:22:35.313813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2022-04-18 14:22:35.313856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-04-18 14:22:35.313869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2022-04-18 14:22:35.313891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2022-04-18 14:22:35.313992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:22:35.314477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:22:35.314931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-15000\n",
            "I0418 14:22:35.317047 139739744683904 saver.py:1284] Restoring parameters from training/model.ckpt-15000\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "I0418 14:22:35.725266 139739744683904 builder_impl.py:665] Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0418 14:22:35.725436 139739744683904 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: training/export/Servo/temp-b'1650291752'/saved_model.pb\n",
            "I0418 14:22:36.370493 139739744683904 builder_impl.py:425] SavedModel written to: training/export/Servo/temp-b'1650291752'/saved_model.pb\n",
            "INFO:tensorflow:Loss for final step: 4.210401.\n",
            "I0418 14:22:36.669044 139739744683904 estimator.py:371] Loss for final step: 4.210401.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python object_detection/export_tflite_ssd_graph.py  --pipeline_config_path={pipeline_fname}  --trained_checkpoint_prefix=training/model.ckpt-15000 --output_directory exported_model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bebJZxLfBKq9",
        "outputId": "ead3a6a8-234e-45bb-fe26-148c73415276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0418 14:23:08.608226 140262754219904 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 14:23:10.613314 140262754219904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 14:23:10.641621 140262754219904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 14:23:10.668663 140262754219904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 14:23:10.695093 140262754219904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 14:23:10.721655 140262754219904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0418 14:23:10.749682 140262754219904 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "2022-04-18 14:23:10.787526: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2022-04-18 14:23:10.814435: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:23:10.814997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-04-18 14:23:10.815282: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-04-18 14:23:10.816905: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2022-04-18 14:23:10.817781: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2022-04-18 14:23:10.818074: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2022-04-18 14:23:10.819772: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-04-18 14:23:10.820825: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2022-04-18 14:23:10.824158: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-04-18 14:23:10.824263: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:23:10.824807: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:23:10.825304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2022-04-18 14:23:10.830199: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2022-04-18 14:23:10.830431: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559ebcd14000 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-04-18 14:23:10.830457: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2022-04-18 14:23:11.017354: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:23:11.018070: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559ebcd14e00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2022-04-18 14:23:11.018103: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2022-04-18 14:23:11.018265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:23:11.018801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-04-18 14:23:11.018859: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-04-18 14:23:11.018971: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2022-04-18 14:23:11.019017: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2022-04-18 14:23:11.019033: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2022-04-18 14:23:11.019049: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-04-18 14:23:11.019062: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2022-04-18 14:23:11.019075: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-04-18 14:23:11.019153: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:23:11.019714: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:23:11.020226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2022-04-18 14:23:11.020278: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-04-18 14:23:11.021392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-04-18 14:23:11.021416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2022-04-18 14:23:11.021426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2022-04-18 14:23:11.021527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:23:11.022074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:23:11.022561: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-04-18 14:23:11.022593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0418 14:23:11.348518 140262754219904 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2022-04-18 14:23:11.779553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:23:11.780139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-04-18 14:23:11.780211: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-04-18 14:23:11.780228: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2022-04-18 14:23:11.780243: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2022-04-18 14:23:11.780256: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2022-04-18 14:23:11.780272: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-04-18 14:23:11.780285: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2022-04-18 14:23:11.780298: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-04-18 14:23:11.780366: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:23:11.780888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:23:11.781364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2022-04-18 14:23:11.781398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-04-18 14:23:11.781409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2022-04-18 14:23:11.781416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2022-04-18 14:23:11.781501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:23:11.782026: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:23:11.782516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-15000\n",
            "I0418 14:23:11.783511 140262754219904 saver.py:1284] Restoring parameters from training/model.ckpt-15000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0418 14:23:12.611355 140262754219904 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0418 14:23:12.611590 140262754219904 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 324 variables.\n",
            "I0418 14:23:12.855118 140262754219904 graph_util_impl.py:334] Froze 324 variables.\n",
            "INFO:tensorflow:Converted 324 variables to const ops.\n",
            "I0418 14:23:12.902726 140262754219904 graph_util_impl.py:394] Converted 324 variables to const ops.\n",
            "2022-04-18 14:23:12.985078: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tflite_convert --input_shape=1,300,300,3 \\\n",
        "    --input_arrays=normalized_input_image_tensor \\\n",
        "    --output_arrays=TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3 \\\n",
        "    --allow_custom_ops \\\n",
        "    --graph_def_file=exported_model/tflite_graph.pb \\\n",
        "    --output_file=detect.tflite"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMl8VFNrDNhA",
        "outputId": "4bdb6a69-d6d6-4e46-d417-d8c00497fac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-18 14:23:22.128480: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2022-04-18 14:23:22.157635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:23:22.158294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-04-18 14:23:22.158562: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-04-18 14:23:22.160281: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2022-04-18 14:23:22.161221: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2022-04-18 14:23:22.161491: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2022-04-18 14:23:22.163210: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-04-18 14:23:22.164259: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2022-04-18 14:23:22.167803: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-04-18 14:23:22.167913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:23:22.168491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:23:22.169013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2022-04-18 14:23:22.174261: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2022-04-18 14:23:22.174493: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d143a29480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-04-18 14:23:22.174523: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2022-04-18 14:23:22.366329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:23:22.367108: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d147f90540 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2022-04-18 14:23:22.367145: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2022-04-18 14:23:22.367305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:23:22.367842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-04-18 14:23:22.367910: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-04-18 14:23:22.367926: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2022-04-18 14:23:22.367940: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2022-04-18 14:23:22.367952: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2022-04-18 14:23:22.367964: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-04-18 14:23:22.367977: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2022-04-18 14:23:22.367990: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-04-18 14:23:22.368044: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:23:22.368549: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:23:22.369035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2022-04-18 14:23:22.369087: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-04-18 14:23:22.370045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-04-18 14:23:22.370069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2022-04-18 14:23:22.370078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2022-04-18 14:23:22.370169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:23:22.370716: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-18 14:23:22.371258: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-04-18 14:23:22.371300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/models/research/detect.tflite')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eWOyPXN14nNq",
        "outputId": "3a3bf17d-21b4-4161-9203-54c26fa6da4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ccebba3b-8014-4ddb-8cf5-9de1b72fb807\", \"detect.tflite\", 18439656)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls {model_dir}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8zbDxdIF_K5",
        "outputId": "6e7bc36d-aee4-4c6f-aacb-6b2ec90afcd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoint\n",
            "eval_0\n",
            "events.out.tfevents.1650121522.3fbc7efda464\n",
            "export\n",
            "graph.pbtxt\n",
            "model.ckpt-10000.data-00000-of-00001\n",
            "model.ckpt-10000.index\n",
            "model.ckpt-10000.meta\n",
            "model.ckpt-5899.data-00000-of-00001\n",
            "model.ckpt-5899.index\n",
            "model.ckpt-5899.meta\n",
            "model.ckpt-7060.data-00000-of-00001\n",
            "model.ckpt-7060.index\n",
            "model.ckpt-7060.meta\n",
            "model.ckpt-8255.data-00000-of-00001\n",
            "model.ckpt-8255.index\n",
            "model.ckpt-8255.meta\n",
            "model.ckpt-9449.data-00000-of-00001\n",
            "model.ckpt-9449.index\n",
            "model.ckpt-9449.meta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/models/research/object_detection/export_tflite_ssd_graph.py  --pipeline_config_path=ssd_mobilenet_v1_coco.config  --trained_checkpoint_prefix=train/model.ckpt-103512 --output_directory exported_model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQQXBnjfU9DK",
        "outputId": "aa8f797a-91ce-4794-8673-15f39eb98335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/models/research/object_detection/export_tflite_ssd_graph.py\", line 143, in <module>\n",
            "    tf.app.run(main)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 312, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 258, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/models/research/object_detection/export_tflite_ssd_graph.py\", line 134, in main\n",
            "    text_format.Merge(f.read(), pipeline_config)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/lib/io/file_io.py\", line 122, in read\n",
            "    self._preread_check()\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/lib/io/file_io.py\", line 84, in _preread_check\n",
            "    compat.as_bytes(self.__name), 1024 * 512)\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: ssd_mobilenet_v1_coco.config; No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "training_path = '/content/models/research/training'\n",
        "files.download(training_path)"
      ],
      "metadata": {
        "id": "Mazpe81bK4xY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "25ab50e5-fbc5-48c2-c36a-69cb14c72f53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0b5b6dfa-fea6-4133-8157-aaa65ae03607\", \"training\", 4096)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(label_map_pbtxt_fname)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QdFDTY31K4v1",
        "outputId": "3e388118-2254-41d4-d961-1fa8f899e066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fd1d4c55-de9d-4afc-bce3-7535bec65553\", \"fire_label_map.pbtxt\", 73)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(pipeline_fname)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "redLPsq9K4t9",
        "outputId": "55a9bfe2-1310-4142-b631-fcb531f11323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3b13ef25-8f38-4f2c-81f0-af7910054a53\", \"ssd_mobilenet_v2_coco.config\", 4841)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZn23kSqK4sw",
        "outputId": "f54b92e5-67ae-475a-d31a-fb9a5c58d012"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "GquQkgujh3qy",
        "outputId": "37443855-8eaf-4ced-b05f-3fd29980962e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tflite_convert --input_shape=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays=TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3 --allow_custom_ops --graph_def_file=exported_model/tflite_graph.pb --output_file=detect.tflite\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5Y8m8lwQNSw",
        "outputId": "f7ebe29c-ab65-4c54-b46b-ffb91b319767"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-16 16:45:44.651819: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2022-04-16 16:45:44.658326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-16 16:45:44.659134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.562\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-04-16 16:45:44.659404: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-04-16 16:45:44.661379: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2022-04-16 16:45:44.662421: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2022-04-16 16:45:44.662768: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2022-04-16 16:45:44.664943: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-04-16 16:45:44.666141: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2022-04-16 16:45:44.670429: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-04-16 16:45:44.670565: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-16 16:45:44.671429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-16 16:45:44.672287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2022-04-16 16:45:44.678038: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2022-04-16 16:45:44.678304: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561bfc5ed640 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-04-16 16:45:44.678339: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2022-04-16 16:45:44.770141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-16 16:45:44.770977: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561bfc5ed800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2022-04-16 16:45:44.771016: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2022-04-16 16:45:44.771196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-16 16:45:44.771947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.562\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-04-16 16:45:44.772063: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-04-16 16:45:44.772113: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2022-04-16 16:45:44.772152: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2022-04-16 16:45:44.772218: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2022-04-16 16:45:44.772251: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-04-16 16:45:44.772310: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2022-04-16 16:45:44.772348: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-04-16 16:45:44.772441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-16 16:45:44.773252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-16 16:45:44.773927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2022-04-16 16:45:44.773984: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-04-16 16:45:44.775252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-04-16 16:45:44.775281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2022-04-16 16:45:44.775297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2022-04-16 16:45:44.775440: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-16 16:45:44.776299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-04-16 16:45:44.776961: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-04-16 16:45:44.777011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10757 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "Ignore 'tcmalloc: large alloc' warnings.\n",
            "Traceback (most recent call last):\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/lite/python/lite.py\", line 674, in from_frozen_graph\n",
            "    graph_def.ParseFromString(file_content)\n",
            "google.protobuf.message.DecodeError: Error parsing message\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/tensorflow-1.15.2/python3.7/bin/tflite_convert\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/lite/python/tflite_convert.py\", line 515, in main\n",
            "    app.run(main=run_main, argv=sys.argv[:1])\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 312, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 258, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/lite/python/tflite_convert.py\", line 511, in run_main\n",
            "    _convert_tf1_model(tflite_flags)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/lite/python/tflite_convert.py\", line 124, in _convert_tf1_model\n",
            "    converter = _get_toco_converter(flags)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/lite/python/tflite_convert.py\", line 111, in _get_toco_converter\n",
            "    return converter_fn(**converter_kwargs)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/lite/python/lite.py\", line 681, in from_frozen_graph\n",
            "    file_content = file_content.decode(\"utf-8\")\n",
            "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe0 in position 8: invalid continuation byte\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzFL-pvXQUag",
        "outputId": "7200ff4c-6910-402c-ecf9-5c7e0850debf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model \n",
        "import tensorflow as tf\n",
        "\n",
        "##pb.형식에서 tflite\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model('/content/models/research/fine_tuned_model/saved_model')\n",
        "tflite_quant_model = converter.convert()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        },
        "id": "C1Ci7t-Udn6R",
        "outputId": "2d30160b-6cce-4a6d-ccbf-56281f35f831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n",
            "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'serving_default'}\n",
            "INFO:tensorflow:input tensors info: \n",
            "INFO:tensorflow:Tensor's key in saved_model's tensor_map: inputs\n",
            "INFO:tensorflow: tensor name: image_tensor:0, shape: (-1, -1, -1, 3), type: DT_UINT8\n",
            "INFO:tensorflow:output tensors info: \n",
            "INFO:tensorflow:Tensor's key in saved_model's tensor_map: detection_classes\n",
            "INFO:tensorflow: tensor name: detection_classes:0, shape: (-1, 100), type: DT_FLOAT\n",
            "INFO:tensorflow:Tensor's key in saved_model's tensor_map: raw_detection_scores\n",
            "INFO:tensorflow: tensor name: raw_detection_scores:0, shape: (-1, -1, 3), type: DT_FLOAT\n",
            "INFO:tensorflow:Tensor's key in saved_model's tensor_map: num_detections\n",
            "INFO:tensorflow: tensor name: num_detections:0, shape: (-1), type: DT_FLOAT\n",
            "INFO:tensorflow:Tensor's key in saved_model's tensor_map: detection_multiclass_scores\n",
            "INFO:tensorflow: tensor name: detection_multiclass_scores:0, shape: (-1, 100, 3), type: DT_FLOAT\n",
            "INFO:tensorflow:Tensor's key in saved_model's tensor_map: detection_boxes\n",
            "INFO:tensorflow: tensor name: detection_boxes:0, shape: (-1, 100, 4), type: DT_FLOAT\n",
            "INFO:tensorflow:Tensor's key in saved_model's tensor_map: detection_scores\n",
            "INFO:tensorflow: tensor name: detection_scores:0, shape: (-1, 100), type: DT_FLOAT\n",
            "INFO:tensorflow:Tensor's key in saved_model's tensor_map: raw_detection_boxes\n",
            "INFO:tensorflow: tensor name: raw_detection_boxes:0, shape: (-1, -1, 4), type: DT_FLOAT\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-284a275c8601>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m##pb.형식에서 tflite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/models/research/fine_tuned_model/saved_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtflite_quant_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    894\u001b[0m               \u001b[0;34m\"None is only supported in the 1st dimension. Tensor '{0}' has \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m               \"invalid shape '{1}'.\".format(\n\u001b[0;32m--> 896\u001b[0;31m                   _get_tensor_name(tensor), shape_list))\n\u001b[0m\u001b[1;32m    897\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mshape_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mshape_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: None is only supported in the 1st dimension. Tensor 'image_tensor' has invalid shape '[None, None, None, 3]'."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/models/research/fine_tuned_model.zip /content/models/research/fine_tuned_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clTEBS0xK4rK",
        "outputId": "9029ecc9-e72b-4e6b-b07c-70c3fb453674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/models/research/fine_tuned_model/ (stored 0%)\n",
            "  adding: content/models/research/fine_tuned_model/checkpoint (deflated 42%)\n",
            "  adding: content/models/research/fine_tuned_model/model.ckpt.data-00000-of-00001 (deflated 7%)\n",
            "  adding: content/models/research/fine_tuned_model/pipeline.config (deflated 70%)\n",
            "  adding: content/models/research/fine_tuned_model/saved_model/ (stored 0%)\n",
            "  adding: content/models/research/fine_tuned_model/saved_model/saved_model.pb (deflated 10%)\n",
            "  adding: content/models/research/fine_tuned_model/saved_model/variables/ (stored 0%)\n",
            "  adding: content/models/research/fine_tuned_model/model.ckpt.meta (deflated 93%)\n",
            "  adding: content/models/research/fine_tuned_model/model.ckpt.index (deflated 68%)\n",
            "  adding: content/models/research/fine_tuned_model/frozen_inference_graph.pb (deflated 10%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "PATH_TO_CKPT = pb_fname\n",
        "\n",
        "PATH_TO_LABELS = label_map_pbtxt_fname\n",
        "\n",
        "PATH_TO_TEST_IMAGES_DIR =  os.path.join(repo_dir_path, \"test\")\n",
        "\n",
        "assert os.path.isfile(pb_fname)\n",
        "assert os.path.isfile(PATH_TO_LABELS)\n",
        "TEST_IMAGE_PATHS = '/content/pan-fire.jpg'\n",
        "assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n",
        "print(TEST_IMAGE_PATHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCecvhxjK4pI",
        "outputId": "5ec7c752-4b99-44af-d307-541b44ca1d25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pan-fire.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map, max_num_classes=num_classes, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "\n",
        "def load_image_into_numpy_array(image):\n",
        "    (im_width, im_height) = image.size\n",
        "    return np.array(image.getdata()).reshape(\n",
        "        (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "IMAGE_SIZE = (12, 8)\n",
        "\n",
        "\n",
        "def run_inference_for_single_image(image, graph):\n",
        "    with graph.as_default():\n",
        "        with tf.Session() as sess:\n",
        "            \n",
        "            ops = tf.get_default_graph().get_operations()\n",
        "            all_tensor_names = {\n",
        "                output.name for op in ops for output in op.outputs}\n",
        "            tensor_dict = {}\n",
        "            for key in [\n",
        "                'num_detections', 'detection_boxes', 'detection_scores',\n",
        "                'detection_classes', 'detection_masks'\n",
        "            ]:\n",
        "                tensor_name = key + ':0'\n",
        "                if tensor_name in all_tensor_names:\n",
        "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "                        tensor_name)\n",
        "            if 'detection_masks' in tensor_dict:\n",
        "               \n",
        "                detection_boxes = tf.squeeze(\n",
        "                    tensor_dict['detection_boxes'], [0])\n",
        "                detection_masks = tf.squeeze(\n",
        "                    tensor_dict['detection_masks'], [0])\n",
        "               \n",
        "                real_num_detection = tf.cast(\n",
        "                    tensor_dict['num_detections'][0], tf.int32)\n",
        "                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n",
        "                                           real_num_detection, -1])\n",
        "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n",
        "                                           real_num_detection, -1, -1])\n",
        "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "                detection_masks_reframed = tf.cast(\n",
        "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "                \n",
        "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "                    detection_masks_reframed, 0)\n",
        "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "            \n",
        "            output_dict = sess.run(tensor_dict,\n",
        "                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "            output_dict['num_detections'] = int(\n",
        "                output_dict['num_detections'][0])\n",
        "            output_dict['detection_classes'] = output_dict[\n",
        "                'detection_classes'][0].astype(np.uint8)\n",
        "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "            if 'detection_masks' in output_dict:\n",
        "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "    return output_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "Frvoidi-K4mI",
        "outputId": "08fedb5b-4f85-46c2-8c1a-f123e2f12ddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-78fd93b41e0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mlabel_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_labelmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_TO_LABELS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m categories = label_map_util.convert_label_map_to_categories(\n\u001b[1;32m     13\u001b[0m     label_map, max_num_classes=num_classes, use_display_name=True)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'label_map_util' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "DsxO1ZHoK4km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = TEST_IMAGE_PATHS\n",
        "image = Image.open(image_path)\n",
        "\n",
        "image_np = load_image_into_numpy_array(image)\n",
        "\n",
        "image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "\n",
        "output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "\n",
        "vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "    image_np,\n",
        "    output_dict['detection_boxes'],\n",
        "    output_dict['detection_classes'],\n",
        "    output_dict['detection_scores'],\n",
        "    category_index,\n",
        "    instance_masks=output_dict.get('detection_masks'),\n",
        "    use_normalized_coordinates=True,\n",
        "    line_thickness=8)\n",
        "plt.figure(figsize=IMAGE_SIZE)\n",
        "plt.imshow(image_np)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "yaJoGgy8K4jC",
        "outputId": "0c27a315-c6f9-40bb-82cb-4ff585e37112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-67dc7719b0d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTEST_IMAGE_PATHS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimage_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image_into_numpy_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-f2tUMXcK4hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "W8dFhI3gK4f3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "I2mj2GRCK4dD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WDf-4WAuK4bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DAsJgeFvK4Yr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}